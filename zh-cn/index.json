[{"categories":["SEM"],"content":"了解如何通过市场调研、关键词优化和广告扩展，撰写高效的SEM文案。本文提供实用的A/B测试方法和工具推荐，助你提高广告效果，实现更高的点击率与转化率！","date":"2024-09-28","objectID":"/zh-cn/posts/create-sem-copy/","tags":["SEM"],"title":"提升点击率与转化率：掌握SEM文案的必备技巧","uri":"/zh-cn/posts/create-sem-copy/"},{"categories":["SEM"],"content":"什么是SEM文案？ SEM（搜索引擎营销）文案是专门为在线广告创建的文本内容，旨在吸引用户点击并提升转化率。SEM文案不仅要吸引眼球，还需具备实用性，能够引导潜在用户采取行动，直接影响广告的效果与ROI。 ","date":"2024-09-28","objectID":"/zh-cn/posts/create-sem-copy/:1:0","tags":["SEM"],"title":"提升点击率与转化率：掌握SEM文案的必备技巧","uri":"/zh-cn/posts/create-sem-copy/"},{"categories":["SEM"],"content":"理解SEM广告的构成：三个主要元素 标题：用户在搜索结果中第一眼看到的部分。一个引人注目的标题能够有效地吸引用户的注意力，激发他们的点击欲望。 描述：标题下方的内容，详细阐述产品或服务的特点和优势。它应以解决用户需求为导向，清晰传达价值主张。 URL：显示的链接地址，影响用户的决策。清晰且具有相关性的URL能够增加用户的信任感，提升点击率。 显示URL：在广告中显示给用户的链接，通常简短且与广告内容相关。 目标URL：用户点击广告后跳转到的实际网页地址。 ","date":"2024-09-28","objectID":"/zh-cn/posts/create-sem-copy/:1:1","tags":["SEM"],"title":"提升点击率与转化率：掌握SEM文案的必备技巧","uri":"/zh-cn/posts/create-sem-copy/"},{"categories":["SEM"],"content":"各广告平台对SEM文案的要求 平台 标题 描述 URL Google Ads 最多30个字符 最多90个字符 建议简洁明了 Bing Ads 最多30个字符 最多90个字符 建议简短且相关 Yahoo 最多30个字符 最多90个字符 建议简短且相关 Baidu 最多40个字符 最多80个字符 URL需清晰 Yandex 最多30个字符 最多90个字符 建议简洁明了 DuckDuckGo 最多30个字符 最多90个字符 URL需清晰 ","date":"2024-09-28","objectID":"/zh-cn/posts/create-sem-copy/:1:2","tags":["SEM"],"title":"提升点击率与转化率：掌握SEM文案的必备技巧","uri":"/zh-cn/posts/create-sem-copy/"},{"categories":["SEM"],"content":"怎么写出好的SEM文案？ ","date":"2024-09-28","objectID":"/zh-cn/posts/create-sem-copy/:2:0","tags":["SEM"],"title":"提升点击率与转化率：掌握SEM文案的必备技巧","uri":"/zh-cn/posts/create-sem-copy/"},{"categories":["SEM"],"content":"1. 充分调研 写出好的SEM文案的第一步是充分的调研与规划，包括： 确定你的独特卖点（USP） USP（Unique selling proposition）是指你的产品或服务相较于竞争对手的独特优势。在这一步你需要确定目标用户的需求、痛点和偏好，分析用户的购买决策过程，了解他们关注的因素（如价格、质量、服务等）。 方法： 进行市场调研和用户访谈，以获取直接反馈。 创建用户画像，描绘出典型客户的特征和行为模式。 工具： SurveyMonkey 或 Google Forms：用于设计和分发在线问卷。 HubSpot Persona Generator：创建详细的用户画像。 关键词研究 关键词是用户在搜索引擎中输入的词语。通过有效的关键词研究，可以识别用户的搜索意图和需求，从而优化你的文案，提高广告的可见性和点击率。这一步最重要的是确定用户的真实搜索意图，即理解用户在搜索时的目标，是获取信息、比较产品还是直接购买。同时，你需要确定关键词的分类，包括信息型关键词、交易型关键词等。 方法： 分析相关话题和用户可能提出的问题，帮助识别潜在关键词。 观察社交媒体和论坛，了解用户讨论的热点和关注点。 利用关键词工具查找相关关键词，分析每个关键词的潜力。 重点关注长尾关键词，这些关键词通常竞争较小，转化率更高。 工具： AnswerThePublic：生成与特定主题相关的问句，帮助识别信息型关键词。 Google Trends：分析关键词的搜索趋势和流行度。 Google Keyword Planner：提供关键词的搜索量和竞争情况，帮助制定广告策略。 SEMrush 或 Ahrefs：分析关键词的排名情况和流量潜力。 落地页一致性 落地页是用户点击广告后访问的页面。确保你的广告文案与落地页内容一致，以提供一致的用户体验，是提升转化率的关键。广告文案承诺的内容必须在着陆页上得到满足，避免用户感到失望。 方法： 比较广告文案和着陆页内容，确保关键点和价值主张一致。 使用相似的标题和描述，以增强用户的信任感。 工具： Grammarly：检查文案的一致性和语法错误。 Google Optimize：测试不同版本的着陆页，观察转化效果。 竞品SEM文案分析 收集和研究竞争对手的SEM文案，分析他们的成功之处和不足之处，找到改进和差异化的机会，从而制定更有效的文案策略。 方法： 在搜索引擎中使用你的关键词，观察排名前列的竞争对手的广告。 保存广告文案和截图，以便后续分析。 比较你的USP与竞争对手的文案，找出能够加强的领域。 工具： SWOT分析工具：帮助你系统性地评估竞争对手的强弱。 SEMrush：查看竞争对手的广告历史和策略。 AdSpy：分析社交媒体和搜索引擎上的竞争对手广告。 ","date":"2024-09-28","objectID":"/zh-cn/posts/create-sem-copy/:2:1","tags":["SEM"],"title":"提升点击率与转化率：掌握SEM文案的必备技巧","uri":"/zh-cn/posts/create-sem-copy/"},{"categories":["SEM"],"content":"2. 开始撰写 在讨论更加细节的撰写技巧之前，需要明确的是，无论你的产品或服务是什么，SEM文案撰写的核心原则都是：迎合你的目标受众的痛点。一旦偏离了这个原则，你的广告转化率肯定会受负面影响（即使点击率很不错）。 在撰写SEM文案时，关键在于如何吸引用户并促使他们采取行动。假设我们以一款环保水瓶为例，这个产品不仅解决了用户的需求，还具备社会责任感。我们将通过几个关键要素来展示如何撰写出高效的SEM文案，使其既能抓住目标受众的注意，又能提升转化率。 插入目标关键词 将相关关键词自然地融入文案中，以提高广告的搜索可见性和点击率。假设你销售环保水瓶，关键词可以是“可重复使用水瓶”、“环保水瓶”。 正面案例： 广告标题：“环保水瓶，助你减少塑料浪费” 描述：“购买我们的可重复使用水瓶，享受10%优惠！保持饮水健康，拯救地球！” 反面案例： 标题：“买水瓶就来这里！” 描述：“我们有很多选择！”（没有使用关键词） 通过有效的关键词插入，用户在搜索时更容易找到你的广告，提高了点击率，而反面案例则可能导致广告被忽视。 社会证言和公众推荐 利用用户评价和推荐信来增强广告的可信度。社会证言能够帮助潜在客户建立信任，尤其是在竞争激烈的市场中。客户看到其他用户的积极反馈，更可能点击广告并最终购买。 正面案例： 在广告中引用真实用户的评价，比如：“这款水瓶真的改变了我的生活，使用起来方便又环保！——张小姐” 反面案例： “我们的水瓶很好用，欢迎大家购买！”（缺乏具体的用户反馈） 反面案例缺乏具体用户的推荐，可能导致客户产生怀疑，从而不愿意购买。 强有力且清晰的CTA（号召性用语） CTA是引导用户采取行动的关键元素，必须简洁明了。清晰的CTA能够消除用户的疑虑，明确告诉他们下一步该做什么，从而提高转化率。 正面案例： 在广告中使用强有力的CTA，比如：“立即购买，享受限时9折优惠！” 反面案例： “想要了解更多信息？”（模糊且不明确） 反面案例没有明确引导用户的下一步，可能导致潜在客户感到迷茫，从而错失购买机会。 使用数字和统计数据 数字和统计数据能够有效增强文案的说服力。具体的数字使文案更具权威性，能够更好地吸引用户的注意，增强购买的信心。 正面案例： “90%的用户反馈，使用我们的环保水瓶后减少了30%的塑料使用！” 反面案例： “我们的水瓶很受欢迎！” 反面案例缺乏具体数据，使得广告缺乏说服力，用户可能不信服，降低了点击和购买的意愿。 创造紧迫感 通过时间限制或稀缺性激励用户快速行动。紧迫感能够刺激用户的购买欲望，避免他们拖延决策，提高转化率。 正面案例： “仅剩100个水瓶，赶快抢购！活动仅限48小时！” 反面案例： “我们随时都有库存，欢迎购买！” 反面案例缺乏紧迫感，可能导致用户拖延决策，从而错失购买机会。 使用以好处为导向的语言 强调用户能够获得的好处，而不仅仅是产品的特点。好处导向的语言能够激发用户的情感共鸣，让他们意识到产品的价值，从而更容易做出购买决策。 正面案例： “通过使用我们的水瓶，你不仅能保持水分充足，还能为保护环境贡献一份力量！” 反面案例： “我们的水瓶有很多颜色可供选择。” 反面案例只是列举产品特性，未能触及用户的需求和利益，降低了购买动机。 ","date":"2024-09-28","objectID":"/zh-cn/posts/create-sem-copy/:2:2","tags":["SEM"],"title":"提升点击率与转化率：掌握SEM文案的必备技巧","uri":"/zh-cn/posts/create-sem-copy/"},{"categories":["SEM"],"content":"3. 测试与优化 A/B测试 A/B测试是一种实验方法，通过同时对比两个不同版本的广告文案（版本A和版本B），来评估哪一个版本的表现更好，从而提高SEM文案的点击率（CTR）和转化率（CVR）。 包括以下几个步骤： 明确目标：确定测试的目标，例如提高点击率或增加购买转化。 选择变量：选择要测试的具体元素，比如标题、描述、CTA等。 创建两个版本：设计版本A和版本B，确保其他条件保持一致，以便于比较。 随机分配流量：将用户随机分配到两个版本，确保每个版本获得同等规模的流量。 收集数据：监测每个版本的表现，记录关键指标如点击率、转化率等。 分析结果：评估哪个版本表现更好，基于数据做出决策。 实施优化：选择表现最佳的版本并在广告中上线，同时考虑继续测试其他变量。 一些可用于SEM文案A/B测试的工具： Google Optimize：用于执行A/B测试的强大工具，适合网站和广告文案的测试。 Optimizely：提供全面的A/B测试解决方案，易于使用，适合各类企业。 VWO (Visual Website Optimizer)：可以进行A/B测试、分割测试等，界面友好，适合新手。 Adobe Target：一款企业级的A/B测试工具，适合大规模广告测试。 使用广告扩展 在SEM广告中，广告扩展是增强广告效果的重要工具，可以提供额外的信息和互动选项，最终实现更高的转化率。 Sitelink（网站链接扩展） 在广告中添加额外链接，指向网站的不同部分，如产品页面、客户评价或常见问题等，帮助用户快速找到所需信息，增加点击的机会。 例如：在环保水瓶广告中，添加链接到“客户评价”、“环保理念”、“购买选项”的页面。用户可以直接访问这些链接，了解更多相关信息。 Callout（附加说明扩展） 在广告中添加简短的文本，突出产品的独特优势，如“无 BPA”、“免费送货”、“30天退款保证”，增强广告吸引力，提供更多用户关注的信息，促使他们点击广告。 例如：在环保水瓶广告文本中包含“环保水瓶，免费送货，30天退款保证！”这样的附加说明，让用户感受到额外的价值。 Structured Snippet（结构化片段扩展） 展示产品或服务的特定特性，如“颜色”、“品牌”、“类型”等。为用户提供关键信息，帮助他们在决策过程中做出更快的选择。 例如：在环保水瓶的广告中，使用“颜色：蓝色、绿色、红色”这样的结构化片段，帮助用户快速了解可选颜色。 Location（位置扩展） 显示企业地址，并在广告中提供地图链接，帮助用户找到实体店位置，从而提高到店流量。尤其对于实体店或服务提供商非常有效。 Call（电话扩展） 在广告中添加电话号码，用户可以直接拨打进行咨询，方便用户获取更多信息，提高咨询和转化率。 Price（价格扩展） 在广告中显示产品或服务的价格，帮助用户快速了解费用信息。提高价格透明度，吸引对价格敏感的客户。 例如：在环保水瓶广告中，显示“只需$19.99”，直接让用户了解价格，从而提高购买欲望。 Promotion（促销扩展） 突出当前的促销活动或折扣信息，激励用户立即行动，增加点击率和转化率。 例如：广告中可以包含“现在购买，享受20%折扣！”的促销信息，吸引用户立刻点击。 App（应用扩展） 引导用户下载移动应用，提升应用下载量，增加应用的使用率。 例如：在广告中添加“下载我们的应用，获取独家优惠！”的链接，鼓励用户下载应用程序。 Image（图片扩展） 在广告中添加高质量图片，使广告更生动，增强视觉吸引力，提升用户点击率和品牌认知度。 参考质量得分优化广告效果 质量得分是搜索引擎（如Google）用来评估广告质量和相关性的一个重要指标，通常以1到10的分数表示，得分越高，意味着广告的质量越好。。它通常基于以下几个因素进行评估： 点击率（CTR）：广告在搜索结果中被点击的频率。 广告相关性：广告内容与关键词的匹配程度。 着陆页体验：用户点击广告后访问的页面质量，包括加载速度、内容相关性和用户体验等。 质量得分直接影响广告的排名和每次点击费用（CPC）。得分高的广告不仅可以在搜索结果中获得更好的位置，还能享受更低的点击成本。反之，低质量得分可能导致广告无法展现或需要支付更高的费用。 关注搜索趋势变化 关注搜索趋势变化有助于了解用户的兴趣和需求的变化，从而优化SEM文案和广告策略。通过分析搜索趋势，可以发现热门关键词、季节性变化和用户偏好的转变，及时调整广告内容以提高相关性和点击率。 可以通过以下工具监控关键词搜索热度的变化趋势： Google Trends：通过查看特定关键词的搜索频率，了解其在不同时间和地区的受欢迎程度。 Google Keyword Planner：Google Ads中的工具，可以发现新关键词并分析其搜索量和趋势。 SEMrush：提供全面的SEO和SEM工具，包括关键词分析、竞争对手研究和趋势监测。 Ahrefs：强大的SEO工具，提供关键词研究、内容分析和搜索趋势的监测。 BuzzSumo：用于内容分析和趋势监测，帮助您发现与特定主题相关的热门内容和社交媒体表现。 利用AI提高创作和优化效率 人工智能（AI）技术正在改变SEM文案的创作和优化方式。通过利用AI工具，我们可以提高文案质量、提升效率，并实现数据驱动的决策。 功能 对应工具 简介 自动生成文案 Jasper AI写作助手，根据输入生成多版本广告文案。 Copy.ai 提供多种文案风格，快速生成营销内容。 数据分析与优化 Google Ads 提供广告表现数据分析，帮助识别效果最佳的文案。 SEMrush 监测广告表现，提供优化建议。 关键词优化 Ahrefs 分析关键词趋势和搜索量，优化文案关键词。 Moz Keyword Explorer 提供关键词研究和相关建议。 个性化文案推荐 Dynamic Yield 实现个性化广告内容推荐，基于用户行为数据生成文案。 Evergage 利用实时数据生成个性化的营销内容。 A/B测试优化 Optimizely 自动化A/B测试过程，快速识别最佳文案组合。 Google Optimize 进行A/B测试，分析广告表现并调整文案。 ","date":"2024-09-28","objectID":"/zh-cn/posts/create-sem-copy/:2:3","tags":["SEM"],"title":"提升点击率与转化率：掌握SEM文案的必备技巧","uri":"/zh-cn/posts/create-sem-copy/"},{"categories":["SEM"],"content":"SEM广告文案检查清单 检查项 描述 完成情况 调研与规划 确定独特卖点（USP） 确保明确产品或服务的独特优势，分析用户需求与痛点。 关键词研究 识别用户搜索意图，选择相关关键词，包括长尾关键词。 落地页一致性 确保广告文案与落地页内容一致，以增强用户体验。 竞品SEM文案分析 研究竞争对手的文案，寻找改进和差异化的机会。 撰写文案 插入目标关键词 自然地融入相关关键词，提升搜索可见性。 社会证言和公众推荐 利用真实用户评价增强可信度。 强有力且清晰的CTA 明确引导用户采取行动，使用简洁的号召性用语。 使用数字和统计数据 提供具体数据以增强说服力。 创造紧迫感 通过时间限制或稀缺性激励用户快速行动。 使用以好处为导向的语言 强调用户能获得的好处，触及情感共鸣。 测试与优化 A/B测试 设计并测试不同版本的广告文案，分析表现。 使用广告扩展 添加网站链接、电话、位置等扩展，提供额外信息。 参考质量得分 关注广告的质量得分，优化点击率和转化率。 关注搜索趋势变化 监控关键词搜索热度变化，调整广告内容。 利用AI提高创作和优化效率 通过AI工具提高文案创作质量与效率。 ","date":"2024-09-28","objectID":"/zh-cn/posts/create-sem-copy/:3:0","tags":["SEM"],"title":"提升点击率与转化率：掌握SEM文案的必备技巧","uri":"/zh-cn/posts/create-sem-copy/"},{"categories":["SEM"],"content":"FAQ ","date":"2024-09-28","objectID":"/zh-cn/posts/create-sem-copy/:4:0","tags":["SEM"],"title":"提升点击率与转化率：掌握SEM文案的必备技巧","uri":"/zh-cn/posts/create-sem-copy/"},{"categories":["SEM"],"content":"SEM与广告有什么区别？ SEM（搜索引擎营销）主要指通过搜索引擎来推广产品或服务，通常包括付费搜索广告（如Google Ads）和搜索引擎优化（SEO）。而广告则是更广泛的概念，涵盖所有形式的营销传播，包括电视广告、社交媒体广告、户外广告等。简单来说，SEM专注于在搜索引擎上获取流量，而广告则是任何渠道上的营销活动。 ","date":"2024-09-28","objectID":"/zh-cn/posts/create-sem-copy/:4:1","tags":["SEM"],"title":"提升点击率与转化率：掌握SEM文案的必备技巧","uri":"/zh-cn/posts/create-sem-copy/"},{"categories":["SEM"],"content":"SEM与AdWords是一样的吗？ SEM和AdWords并不完全一样。SEM（搜索引擎营销）是一个广泛的术语，涵盖了所有通过搜索引擎来进行的付费广告和自然搜索优化的活动。而AdWords是谷歌提供的一种具体的付费广告服务（现称为Google Ads），它是SEM的一部分。换句话说，AdWords是实现SEM目标的一种工具，专注于通过Google搜索引擎展示广告。 ","date":"2024-09-28","objectID":"/zh-cn/posts/create-sem-copy/:4:2","tags":["SEM"],"title":"提升点击率与转化率：掌握SEM文案的必备技巧","uri":"/zh-cn/posts/create-sem-copy/"},{"categories":["SEM"],"content":"谷歌广告是SEO还是SEM？ 谷歌广告属于SEM（搜索引擎营销）。SEM包括付费广告和自然搜索优化，而谷歌广告是通过付费在谷歌搜索结果中展示广告的一种方式。SEO（搜索引擎优化）则是通过优化网站内容和结构，提高自然搜索排名的方法。 ","date":"2024-09-28","objectID":"/zh-cn/posts/create-sem-copy/:4:3","tags":["SEM"],"title":"提升点击率与转化率：掌握SEM文案的必备技巧","uri":"/zh-cn/posts/create-sem-copy/"},{"categories":["AI"],"content":"—cref指令全称为“角色参考”（Character Reference），主要用于从参考图片中抽取人物特性，并将其应用至新图像中，以实现人物形象的连贯性和一致性设计。它允许用户指定一个或多个图像作为内容参考。Midjourney将使用这些参考图像来帮助生成具有类似内容的图像。这个功能更适合用于动漫或游戏。 ","date":"2024-09-08","objectID":"/zh-cn/posts/midjourney-cref/:0:0","tags":["AI","Midjourney"],"title":"如何使用Midjourney CREF控制角色一致性","uri":"/zh-cn/posts/midjourney-cref/"},{"categories":["AI"],"content":"适用版本 Midjourney V6 和 Niji V6 ","date":"2024-09-08","objectID":"/zh-cn/posts/midjourney-cref/:1:0","tags":["AI","Midjourney"],"title":"如何使用Midjourney CREF控制角色一致性","uri":"/zh-cn/posts/midjourney-cref/"},{"categories":["AI"],"content":"基础使用方法 prompt提示词 --cref 图片URL 选择清晰的图片作为角色参考，上传到Midjourney中（也可以上传多张）。本文以这张图片为例： 输入以下prompt： japanese animation of a black cat playing in the garden --cref https://s.mj.run/Iq29pwi69zA 可以看到Midjourney按照参考图片中小黑猫的形象生成了新的日本动画风格的图片： ","date":"2024-09-08","objectID":"/zh-cn/posts/midjourney-cref/:2:0","tags":["AI","Midjourney"],"title":"如何使用Midjourney CREF控制角色一致性","uri":"/zh-cn/posts/midjourney-cref/"},{"categories":["AI"],"content":"设置人物参考的权重 —cw（Character weight）参数可用来 调节风格强度，数值范围为0到100。当cw设置为0时，AI只锁定角色的脸部特征，cw设置为100时，AI会锁定整个角色，包括脸部、头发、服装等等。 如果希望生成的图片与参考图片的相似度极高，可以将cw值设置为80到100；如果希望生成的图片更加贴合prompt描述内容，可以将cw值设置为0到30。 以下为不同参数值的参考效果： ","date":"2024-09-08","objectID":"/zh-cn/posts/midjourney-cref/:3:0","tags":["AI","Midjourney"],"title":"如何使用Midjourney CREF控制角色一致性","uri":"/zh-cn/posts/midjourney-cref/"},{"categories":["AI"],"content":"cw=0 ","date":"2024-09-08","objectID":"/zh-cn/posts/midjourney-cref/:3:1","tags":["AI","Midjourney"],"title":"如何使用Midjourney CREF控制角色一致性","uri":"/zh-cn/posts/midjourney-cref/"},{"categories":["AI"],"content":"cw=30 ","date":"2024-09-08","objectID":"/zh-cn/posts/midjourney-cref/:3:2","tags":["AI","Midjourney"],"title":"如何使用Midjourney CREF控制角色一致性","uri":"/zh-cn/posts/midjourney-cref/"},{"categories":["AI"],"content":"cw=60 ","date":"2024-09-08","objectID":"/zh-cn/posts/midjourney-cref/:3:3","tags":["AI","Midjourney"],"title":"如何使用Midjourney CREF控制角色一致性","uri":"/zh-cn/posts/midjourney-cref/"},{"categories":["AI"],"content":"cw=100 ","date":"2024-09-08","objectID":"/zh-cn/posts/midjourney-cref/:3:4","tags":["AI","Midjourney"],"title":"如何使用Midjourney CREF控制角色一致性","uri":"/zh-cn/posts/midjourney-cref/"},{"categories":["AI"],"content":"什么是工作流？ 工作流指的是一组预定义的、标准化的步骤，可以用来完成特定的任务。一个工作流中包含多个节点，每个节点完成一个固定的任务。 举个不太恰当但很容易理解的例子，我们都很熟悉“把大象放进冰箱需要几步？”这个脑筋急转弯，答案是三步：打开冰箱、把大象放进去、关上冰箱。在这个场景中，这三步就构成了“把大象放进冰箱”这个工作流的节点。 ","date":"2024-09-07","objectID":"/zh-cn/posts/how-to-create-a-workflow-in-coze/:1:0","tags":["AI","Coze"],"title":"【手把手教学】Coze如何创建工作流","uri":"/zh-cn/posts/how-to-create-a-workflow-in-coze/"},{"categories":["AI"],"content":"为什么需要使用工作流？ 在之前介绍如何在Coze中创建Bot的文章中，有一个步骤是选择你的Bot期望使用的LLM模型。而LLM模型的能力边界受到“上下文”的限制，当你输入给Bot的信息越多、要求其解决的问题越发杂时，Bot返回给你的答案质量就会下降。相信你在直接使用ChatGPT或Claude时也有过类似的感受。 短期内，我们很难要求大语言模型在处理上下文方面获得显著的能力提升。那么另一个解决方法，就是把输入给Bot的复杂任务拆解为多个简单的子任务，从而保证Bot输出内容的质量。 ","date":"2024-09-07","objectID":"/zh-cn/posts/how-to-create-a-workflow-in-coze/:2:0","tags":["AI","Coze"],"title":"【手把手教学】Coze如何创建工作流","uri":"/zh-cn/posts/how-to-create-a-workflow-in-coze/"},{"categories":["AI"],"content":"Coze工作流功能简介 节点是组成工作流的基本单元，工作流由多个节点构成。Coze中的节点可以分为两类，一类是默认自动生成的固定节点，另一类是可选的基础节点： ","date":"2024-09-07","objectID":"/zh-cn/posts/how-to-create-a-workflow-in-coze/:3:0","tags":["AI","Coze"],"title":"【手把手教学】Coze如何创建工作流","uri":"/zh-cn/posts/how-to-create-a-workflow-in-coze/"},{"categories":["AI"],"content":"默认自动生成的固定节点 Start节点：工作流的起始节点，可以包含用户输入的信息 End节点：工作流的末尾节点，用于返回工作流的运行结果 ","date":"2024-09-07","objectID":"/zh-cn/posts/how-to-create-a-workflow-in-coze/:3:1","tags":["AI","Coze"],"title":"【手把手教学】Coze如何创建工作流","uri":"/zh-cn/posts/how-to-create-a-workflow-in-coze/"},{"categories":["AI"],"content":"可选基础节点 目前，Coze共提供十三个基础节点： 节点名称 描述 Plugin 插件节点。用于使用外部实时数据并处理任务 LLM 大语言模型节点。支持选择不同的AI模型处理文本生成任务 Code 代码节点。通过IDE编写代码处理输入参数，并返回输出值 Knowledge 知识库节点。根据输入参数从关联知识库中召回数据，并返回 Workflow 工作流节点。添加已发布的工作流并执行子任务 Condition if-else 逻辑节点。满足设置条件则运行 if 分支，否则运行 else 分支 Loop 循环节点。通过设置循环的逻辑和次数以重复执行一系列任务 Intent recognition 意图识别节点。用于识别用户输入的意图，将其与预置的意图选项匹配 Text Processing 文本处理节点。用于处理多个字符串类型的变量 Message 消息节点。支持中间过程的消息输出，支持流式和非流式方式 Question 问题节点。支持在对话过程中向用户提问，既有预设选项，也有开放式问题 Variable 变量节点。用于读取和写入 Bot 中的变量 Database 数据库节点。用户可以在开发者控制的数据库中读写数据。必须事先在Bot的数据库中添加一个表 ","date":"2024-09-07","objectID":"/zh-cn/posts/how-to-create-a-workflow-in-coze/:3:2","tags":["AI","Coze"],"title":"【手把手教学】Coze如何创建工作流","uri":"/zh-cn/posts/how-to-create-a-workflow-in-coze/"},{"categories":["AI"],"content":"节点与参数 不同节点可能需要输入不同的参数，输入参数分为Reference和Input两类： Reference参数：指引用前面节点的参数值 Input参数：支持设置自定义的参数值 ","date":"2024-09-07","objectID":"/zh-cn/posts/how-to-create-a-workflow-in-coze/:3:3","tags":["AI","Coze"],"title":"【手把手教学】Coze如何创建工作流","uri":"/zh-cn/posts/how-to-create-a-workflow-in-coze/"},{"categories":["AI"],"content":"如何使用Coze创建工作流 本文会介绍一个我用Coze搭建关键词调研Bot的案例，它可以根据用户输入的目标关键词，在Google中查询和总结相关的信息，并且附带对应的内容链接。 首先，我们需要创建一个Bot（如果不太清楚如何创建，可以看之前的一篇文章），然后点击“工作流”后面的“+”号： 输入工作流的名称和描述，注意命名只能包括字母、数字、下划线，而且要以字母开头。然后点击“确认”： 之后进入工作流编辑页面，可以看到，Coze会自动生成Start节点和End节点。左侧为前面提到的可选的基础节点： 首先，我们需要确定如何从Google中获得我们想要的信息。以往我们更多地直接通过写代码来访问API进而收集到所需要的信息。那么在Coze中，可以直接使用插件来完成这项任务。 点击左侧的“Plugin”按钮，然后选择Google Web Search这款插件并添加： 这个工作流的触发是用户输入的关键词，所以我们需要在Start节点配置字符串类型的参数，用于接收输入的文本，此处命名为query： 关键词信息需要流向Google Web Search插件，由其完成文本处理和检索任务，这里的操作包括： 设置为上一步骤中的query 将开始节点右侧和插件节点左侧连接起来，表示任务之间的顺序 此外，我们还可以设置另外两个参数： num参数：定义返回的最大数量的检索结果数，默认为10 start参数：设置检索的页面数，默认为0，即检索结果第一页 这时我们可以先点击右上角的“Test run”测试一下输出效果。这里我们输入“chatgpt”为例，可以看到Coze花费3秒钟成功运行了这个工作流。点击插件节点右上角的“Display result”可以查看其处理任务的具体结果： 我希望这个工作流最终输出的信息包括：每个检索结果的标题、描述，以及对应的链接。而这些信息是混杂在Google Web Search插件的输出结果中的，那么我需要一个Code节点来提取这些信息。 将Code节点置于插件节点和End节点之间后，input参数设置为插件节点输出的结果，然后点击Edit in IDE进入比代码编辑页面： 目前Code节点支持Python和JavaScript两种语言。如果你不会写代码，也可以通过在内置的AI中输入自然语言prompt让AI帮你写。写完之后点击“Test Code”测试代码是否可以正常运行： 确定代码运行正常后，我们可以再次测试整个工作流的运行情况。虽然此时我们已经能够从Google搜索结果中提取相应的结果标题、链接、摘要，但所有的信息都堆在一起，所以我们还需要一个LLM节点来帮助我们组织信息。为了保证输出结果的质量，prompt中要尽可能讲清楚背景信息： ","date":"2024-09-07","objectID":"/zh-cn/posts/how-to-create-a-workflow-in-coze/:4:0","tags":["AI","Coze"],"title":"【手把手教学】Coze如何创建工作流","uri":"/zh-cn/posts/how-to-create-a-workflow-in-coze/"},{"categories":["AI"],"content":"如何将工作流应用在Coze Bot中 测试工作流能够正常运行后，我们可以点击右上角的“Publish”按钮进行发布，然后在Bot中添加这个工作流（注意：工作流需要发布后才能添加到Bot中）： ","date":"2024-09-07","objectID":"/zh-cn/posts/how-to-create-a-workflow-in-coze/:5:0","tags":["AI","Coze"],"title":"【手把手教学】Coze如何创建工作流","uri":"/zh-cn/posts/how-to-create-a-workflow-in-coze/"},{"categories":["AI"],"content":"—sref指令全称为“风格参考”（Style References），旨在帮助用户复刻和保持图片风格的一致性。其主要作用是允许用户上传一张或多张图片作为风格参考，以指导Midjourney生成与这些参考图风格一致的图像。这个指令在你看到一个非常喜欢的图片，想尝试生成类似或相同风格的图片、而又不知道这是什么风格时特别有用。 ","date":"2024-09-01","objectID":"/zh-cn/posts/midjourney-sref/:0:0","tags":["AI","Midjourney"],"title":"如何使用Midjourney SREF控制风格一致性","uri":"/zh-cn/posts/midjourney-sref/"},{"categories":["AI"],"content":"适用版本 Midjourney V6 和 Niji V6 ","date":"2024-09-01","objectID":"/zh-cn/posts/midjourney-sref/:1:0","tags":["AI","Midjourney"],"title":"如何使用Midjourney SREF控制风格一致性","uri":"/zh-cn/posts/midjourney-sref/"},{"categories":["AI"],"content":"基础使用方法 prompt提示词 --sref 图片URL 有以下三种获得图片URL的方法： 鼠标移动到之前生成过的图片，单击右键，选择“复制消息链接”，然后即可粘贴到prompt中 直接将之前生成过的图片拖拽到输入框中 从本地上传图片 MJ会将图片URL视作一个风格参考，并尝试制作类似风格的内容。 本文将以Midjourney官网的这张图片进行演示： 先将图片上传到Midjourney中，然后输入以下prompt： a cute girl with hat --sref https://s.mj.run/XRxNtTBjwcs --style raw --s 750 --niji 6 可以看到Midjourney根据我们提供的图片风格，绘制了4个戴帽子的小女孩的图片： ","date":"2024-09-01","objectID":"/zh-cn/posts/midjourney-sref/:2:0","tags":["AI","Midjourney"],"title":"如何使用Midjourney SREF控制风格一致性","uri":"/zh-cn/posts/midjourney-sref/"},{"categories":["AI"],"content":"—sref v.s style tuner style tuner可以通过prompt生成一系列的图，然后根据你选择的内容来确定这个模型的风格和方向。可以将style tuner生成的图片作为sref参数的参考URL，下面为prompt示例： Style tuner生成的图片： 依据style tuner的风格，利用sref参数生成的图片： ","date":"2024-09-01","objectID":"/zh-cn/posts/midjourney-sref/:2:1","tags":["AI","Midjourney"],"title":"如何使用Midjourney SREF控制风格一致性","uri":"/zh-cn/posts/midjourney-sref/"},{"categories":["AI"],"content":"—sref v.s 垫图 –sref参数和垫图的prompt格式不同： 垫图： /imagine URL prompt text –v 6 Style reference： /imagine prompt text –v 6 –sref URL 我们用下面这张参考图片来看看生成图片的区别： 使用相同的描述文本和参考图片，垫图更加关注语义内容（如人物、地点、物品等），会参考一小部分风格： 而sref参数则更加关注色彩和风格： ","date":"2024-09-01","objectID":"/zh-cn/posts/midjourney-sref/:2:2","tags":["AI","Midjourney"],"title":"如何使用Midjourney SREF控制风格一致性","uri":"/zh-cn/posts/midjourney-sref/"},{"categories":["AI"],"content":"进阶使用方法 ","date":"2024-09-01","objectID":"/zh-cn/posts/midjourney-sref/:3:0","tags":["AI","Midjourney"],"title":"如何使用Midjourney SREF控制风格一致性","uri":"/zh-cn/posts/midjourney-sref/"},{"categories":["AI"],"content":"设置图片参考的总权重 —sw（Style weight）参数可用来调节风格强度。–sw默认值为100，数值范围为0到1000。数值越高，生成的图片与参考图片的风格就越相似；数值越低，画面就越接近提示词直出的效果。经过测试，至少要15-20才能看出效果，数值在200左右效果较好，超过700画面容易出现扭曲变形。 ","date":"2024-09-01","objectID":"/zh-cn/posts/midjourney-sref/:3:1","tags":["AI","Midjourney"],"title":"如何使用Midjourney SREF控制风格一致性","uri":"/zh-cn/posts/midjourney-sref/"},{"categories":["AI"],"content":"使用多个图片作为风格参考 提示词如下： prompt提示词 --sref 图片一URL 图片二URL 图片三URL ... 例如同时参考上述两张图片的风格生成一张图片： ","date":"2024-09-01","objectID":"/zh-cn/posts/midjourney-sref/:3:2","tags":["AI","Midjourney"],"title":"如何使用Midjourney SREF控制风格一致性","uri":"/zh-cn/posts/midjourney-sref/"},{"categories":["AI"],"content":"设置单个参考图片的权重 使用多张参考图片时，每张图片的参考权重是相同的。可以使用::来指定单张图片的权重，权重数值区间为0到100，例如： ","date":"2024-09-01","objectID":"/zh-cn/posts/midjourney-sref/:3:3","tags":["AI","Midjourney"],"title":"如何使用Midjourney SREF控制风格一致性","uri":"/zh-cn/posts/midjourney-sref/"},{"categories":["AI"],"content":"结合垫图使用 通过垫图让Midjourney学习图片中的元素、构图、内容，–sref指令让Midjourney学习图片风格。注意：中间一定要加文字提示内容，否则会无法生成。 提示词如下： 图片URL prompt提示词 --sref 图片URL 两者同时使用则可兼顾语义内容与风格： ","date":"2024-09-01","objectID":"/zh-cn/posts/midjourney-sref/:3:4","tags":["AI","Midjourney"],"title":"如何使用Midjourney SREF控制风格一致性","uri":"/zh-cn/posts/midjourney-sref/"},{"categories":["AI"],"content":"什么是Coze？ Coze是由字节跳动推出的AI聊天机器人和应用程序编辑开发平台。通过集成多款插件，Coze的Bot能力得到极大扩展，可适用于各种场景，如聊天机器人、数据分析、内容采集等。 ","date":"2024-09-01","objectID":"/zh-cn/posts/how-to-create-bot-on-coze/:1:0","tags":["AI","Coze"],"title":"【手把手教学】Coze怎么创建bot？","uri":"/zh-cn/posts/how-to-create-bot-on-coze/"},{"categories":["AI"],"content":"Coze页面简介 注册成功进入Coze后，在主页，你首先会看到一个助理机器人，它会引导你一步一步了解Coze的功能及作用。 左侧菜单栏包括以下几个部分： 个人空间： 是仅自己可见，用于存放自己做的bot、收藏的bot、插件以及工作流的地方。你也可以通过创建团队空间，与团队成员共享bot和插件等。 Bot商店： Bot，即机器人，通常指能够执行自动化任务的软件程序。在Bot商店，你可以看到Coze官方以及其它用户发布的Bot。此外，如果你选择上架自己创建的Bot，那么它也会出现在商店。 插件商店： 可查看官方和其它用户发布的插件，如GPT4V、Google Web Search、DALLE 3等，可通过“最受欢迎”或“最近”进行排序。 工作流商店： “工作流”指为了完成某项任务而进行的一系列有序的步骤。对于一个较为复杂的任务，我们需要对其进行拆解，拆分为单个步骤，再将每个步骤按照预设的流程和动作进行连接，从而实现自动化完成任务，减少人工的重复操作。在工作流商店，你可以查看并复制他人已经创建好的工作流。你也可以选择自己创建工作流并应用在Bot中。 ","date":"2024-09-01","objectID":"/zh-cn/posts/how-to-create-bot-on-coze/:2:0","tags":["AI","Coze"],"title":"【手把手教学】Coze怎么创建bot？","uri":"/zh-cn/posts/how-to-create-bot-on-coze/"},{"categories":["AI"],"content":"如何通过Coze创建Bot 接下来，我们看下如何通过Coze搭建一个支持中英互译的bot。 ","date":"2024-09-01","objectID":"/zh-cn/posts/how-to-create-bot-on-coze/:3:0","tags":["AI","Coze"],"title":"【手把手教学】Coze怎么创建bot？","uri":"/zh-cn/posts/how-to-create-bot-on-coze/"},{"categories":["AI"],"content":"1. 创建一个bot并完成基础设置 点击左上角的“创建bot”，然后完成以下基础设置： 空间（必填）：选择bot存放的空间，可选“个人空间”或“团队空间” Bot的名字（必填）：我们设置为“English - Chinese Translator” 用户消息账单（必填）：选择是由用户承担还是自己承担对话时消息用量的费用 Bot功能简介（选填）：介绍你的Bot的作用。这些内容会呈现给使用你的Bot的用户 图标（必填）：可直接上传图片，或要求Coze基于你的Bot名字及功能生成一个合适的图标 完成上述设置后即可点击“确认”按钮，进入下一步。 这里简单介绍下Coze关于消息积分的收费： 在与Bot对话时，Coze会按照收到的消息数量进行收费，而消息积分则是用于抵扣在与Bot对话时消息用量的费用（注意，调试Bot时收到的Bot回复数量，也会扣减对应的积分）。 每个账号每天将免费获得10个积分。积分扣减完毕后，和Bot对话时会收到积分不足的提示。如需继续和Bot对话，你可以购买Premium Plan，或单独购买更多积分。 费用根据Bot使用的模型而有所不同： 模型 每条消息消耗的积分 GPT-3.5 Turbo 0.1 GPT-4o mini (128k) Coze free plan：0.1\\n Coze Premium：1 GPT-4o (8k) 2 GPT-4o (32k) 5 GPT-4o (128k) 10 Gemini 1.5 Pro 2.5 Gemini 1.5 Flash 0.5 Claude 3 Haiku 0.1 Claude 3.5 Sonnet 2 ","date":"2024-09-01","objectID":"/zh-cn/posts/how-to-create-bot-on-coze/:3:1","tags":["AI","Coze"],"title":"【手把手教学】Coze怎么创建bot？","uri":"/zh-cn/posts/how-to-create-bot-on-coze/"},{"categories":["AI"],"content":"2. Bot配置 配置界面分为三部分： 左边：支持输入自然语言，设置Bot的角色定位和预设的prompt 中间：设置Bot的技能，支持：插件、工作流、触发器、知识库等 右边：Bot的预览效果 首先，选择Bot的模式。目前Coze支持单agent模式和多agent模式（默认为单agent模式）： 然后，选择Bot想应用的LLM模型，目前支持：Claude、GPT、Gemini，本文以GPT-3.5 Turbo为例。这里的模型选择会影响到前面提到的消费用量的费用： 接下来，我们开始设置Bot的身份和功能。在左侧的命令栏，我告诉Bot：你是一位擅长中英互译的语言专家，当用户输入英文时，你会返回对应的中文（附带拼音）；当用户输入中文时，你会返回对应的英文。然后，我们在右侧的预览栏进行测试：输入“To be or not to be, that is a question.”，发送给Bot。可以看到Bot返回了这句英文的正确中文翻译，并附带了对应的拼音： 如果你担心自己的命令写得不够准确或希望将自然语言转换为更加标准的prompt语言，可以点击右上角的“优化”按钮，由Coze帮你优化prompt。 我们再测试一下中译英的效果，可以看到Bot也能够正确地返回英文翻译： ","date":"2024-09-01","objectID":"/zh-cn/posts/how-to-create-bot-on-coze/:3:2","tags":["AI","Coze"],"title":"【手把手教学】Coze怎么创建bot？","uri":"/zh-cn/posts/how-to-create-bot-on-coze/"},{"categories":["AI"],"content":"3. 发布Bot 当你调试完Bot，确定其能够按照你的要求正确地运行后，可以点击右上角的“发布”按钮，让更多的人看到和使用你的Bot！ ","date":"2024-09-01","objectID":"/zh-cn/posts/how-to-create-bot-on-coze/:3:3","tags":["AI","Coze"],"title":"【手把手教学】Coze怎么创建bot？","uri":"/zh-cn/posts/how-to-create-bot-on-coze/"},{"categories":null,"content":"看了眼之前最后一篇博文的时间，距今天刚好四个月。磕磕绊绊地翻出教程新建了这个文档。 ","date":"2024-08-25","objectID":"/zh-cn/posts/re-update-the-blog-after-four-months/:0:0","tags":null,"title":"时隔四个月重新更新博客","uri":"/zh-cn/posts/re-update-the-blog-after-four-months/"},{"categories":null,"content":"这个博客的起源 之前翻箱倒柜找出了近几年的日记，在欣赏自己过去青涩中二天真的记录的过程中，确定自己是在2022年1月23日创建了这个站点。当时一方面想要找个地方集中记录自己的想法和精力，另一方面莫名其妙地又重新燃起了对编程相关技术技能的兴趣。在体验了CSDN、掘金、博客园、微信公众号、Notion等市面上一系列常见的博文载体后，我还是决定挑战一下，自己用Hugo和GitHub Pages搭一个。 整个过程其实不算顺利，我有的编程知识也只是基本的Java和前端语言。但好在有不少大神写了详细的教程，我花了一个下午加晚上的时间把站点上线了。 Chloe是我给自己起的英文名。当时在某个网站上输入自己的性命拼音，按照姓氏选择了一个比较匹配而且寓意还不错的名字。Evolution是希望通过这个博客记录自己的成长和进化过程。 一开始心血来潮更新了几篇，中间便是长时间的断更。到今年初的时候又开始折腾，结果这次玩脱了，在增加某个配置的时候直接把根目录搞乱了，尝试了几轮回退也没办法恢复到原先的样子，索性咬咬牙直接重建了。这一天是2024年3月28日。 之后又批量更新了几篇竞品调研的博文，但被谷歌收录的量一直不高，严重打击我更新的热情，索性不管了。 ","date":"2024-08-25","objectID":"/zh-cn/posts/re-update-the-blog-after-four-months/:1:0","tags":null,"title":"时隔四个月重新更新博客","uri":"/zh-cn/posts/re-update-the-blog-after-four-months/"},{"categories":null,"content":"决定重新更新博客的原因 想要重新更新是因为在最近几个月获得了太多的信息输入。一方面开始重新有规律地看书，每天差不多都是一个小时的阅读时间；另一方面也开始主动地关注行业和世界的发展趋势，例如AI。信息过于繁杂多样，全部挤在我的脑子里乱飞，时不时地从某个角落探出头来，于是我便被吸引注意力，开始漫无目的地瞎想，然后又被另外冒出来的信息或想法吸引走。我不喜欢这种看似了解了很多，实际上没明白什么的状态。 我开始有意识地整理归纳自己接收到的信息，比如定期清理各个平台的收藏，包括：微博、小红书、公众号、推特、各类社群……同时期望在这个过程中能够稍微窥探到我目前最苦恼的问题的答案：我什么时候可以不上班？ 显然，纸上谈兵是行不通的，我得下场试试。为了避免犯同样的错误，我决定把尝试的经历都写下来，无论成功与否。 ","date":"2024-08-25","objectID":"/zh-cn/posts/re-update-the-blog-after-four-months/:2:0","tags":null,"title":"时隔四个月重新更新博客","uri":"/zh-cn/posts/re-update-the-blog-after-four-months/"},{"categories":null,"content":"接下来希望更新的内容 我发现自己在潜意识里很喜欢同时挑战多个任务，这两次跳槽期间，我都分别开了一个独立站（虽然第一个已经关了，现在这个也没什么起色）。结合今年刚接触的新行业以及对自身未来职业发展的期待，暂时会主要关注以下领域： 数字营销：包括但不限于SEO、SEM、TikTok运营、Pinterest运营、YouTube运营 AI：包括但不限于ChatGPT、Claude、Midjourney 金融\u0026经济学：《经济学原理》不知道翻开过几遍了，至少先建立比较完整的知识体系吧 Hugo：现在这个站点着实是不太好看，还是想装修一下 祝我早日不上班！ ","date":"2024-08-25","objectID":"/zh-cn/posts/re-update-the-blog-after-four-months/:3:0","tags":null,"title":"时隔四个月重新更新博客","uri":"/zh-cn/posts/re-update-the-blog-after-four-months/"},{"categories":["Python"],"content":"使用pandas、scikit-learn的NMF和spaCy从zst文件数据中提取数据以进行数据分析。","date":"2024-04-09","objectID":"/zh-cn/posts/how-to-read-a-zst-file-python/","tags":["Python"],"title":"如何通过 Python 读取 ZST 文件","uri":"/zh-cn/posts/how-to-read-a-zst-file-python/"},{"categories":["Python"],"content":"前提条件 要运行此代码，你需要 pandas、zstandard（zstd）和 json 库。如果尚未安装，你可以使用 pip 安装 pandas 和 zstandard： pip install pandas zstandard json 是 Python 标准库的一部分，因此无需额外安装。 注意：以上内容假设 .zst 文件中的数据为 换行符分隔的 JSON (NDJSON) 格式。如果你的数据采用其他格式（例如 CSV、TSV），则应使用适当的 pandas 函数（如 pd.read_csv()）。 ","date":"2024-04-09","objectID":"/zh-cn/posts/how-to-read-a-zst-file-python/:1:0","tags":["Python"],"title":"如何通过 Python 读取 ZST 文件","uri":"/zh-cn/posts/how-to-read-a-zst-file-python/"},{"categories":["Python"],"content":"函数定义 设计一个名为 decompress_zst_to_csv 的 Python 函数，用于解压包含 JSON 对象的 .zst（Zstandard 压缩）文件，将这些对象转换为 pandas DataFrame，然后将此 DataFrame 导出到 CSV 文件。让我们分解一下函数的每个部分如何工作： def decompress_zst_to_csv(zst_file_path, output_csv_path): 此行定义了一个函数 decompress_zst_to_csv，它接受两个参数：zst_file_path（要解压的 .zst 文件的路径）和 output_csv_path（要保存生成的 CSV 文件的路径）。 ","date":"2024-04-09","objectID":"/zh-cn/posts/how-to-read-a-zst-file-python/:2:0","tags":["Python"],"title":"如何通过 Python 读取 ZST 文件","uri":"/zh-cn/posts/how-to-read-a-zst-file-python/"},{"categories":["Python"],"content":"创建 Zstandard 解压器 dctx = zstd.ZstdDecompressor() 此处实例化 zstd 模块中的 ZstdDecompressor 对象。此对象用于解压使用 Zstandard (.zst) 压缩的数据。 ","date":"2024-04-09","objectID":"/zh-cn/posts/how-to-read-a-zst-file-python/:2:1","tags":["Python"],"title":"如何通过 Python 读取 ZST 文件","uri":"/zh-cn/posts/how-to-read-a-zst-file-python/"},{"categories":["Python"],"content":"初始化数据列表 data_list = [] 初始化一个空列表 data_list，用于存储解压后的 JSON 对象。 ","date":"2024-04-09","objectID":"/zh-cn/posts/how-to-read-a-zst-file-python/:2:2","tags":["Python"],"title":"如何通过 Python 读取 ZST 文件","uri":"/zh-cn/posts/how-to-read-a-zst-file-python/"},{"categories":["Python"],"content":"打开并解压 .zst 文件 with open(zst_file_path, 'rb') as compressed: with dctx.stream_reader(compressed) as reader: text_stream = io.TextIOWrapper(reader, encoding='utf-8') for line in text_stream: data = json.loads(line) data_list.append(data) 此块以二进制读取模式 ('rb') 打开 .zst 文件。然后，它使用 ZstdDecompressor 的 stream_reader 方法动态解压文件内容。解压后的数据流被包装在 TextIOWrapper 中，以便逐行读取流作为文本（使用 UTF-8 编码）。每行应为一个 JSON 对象，使用 json.loads 将其解析为 Python 字典并附加到 data_list。 ","date":"2024-04-09","objectID":"/zh-cn/posts/how-to-read-a-zst-file-python/:2:3","tags":["Python"],"title":"如何通过 Python 读取 ZST 文件","uri":"/zh-cn/posts/how-to-read-a-zst-file-python/"},{"categories":["Python"],"content":"转换为 DataFrame 并导出到 CSV df = pd.DataFrame(data_list) df.to_csv(output_csv_path, index=False) 在读取所有 JSON 对象并将其存储在 data_list 中后，此字典列表将转换为 pandas DataFrame。最后，将 DataFrame 导出到 output_csv_path 指定的 CSV 文件，并使用 index=False 以防止 pandas 将行索引写入 CSV 文件。 ","date":"2024-04-09","objectID":"/zh-cn/posts/how-to-read-a-zst-file-python/:2:4","tags":["Python"],"title":"如何通过 Python 读取 ZST 文件","uri":"/zh-cn/posts/how-to-read-a-zst-file-python/"},{"categories":["Python"],"content":"使用示例 decompress_zst_to_csv('sample.zst', 'output.csv') 此行演示如何调用 decompress_zst_to_csv 函数，指定输入 .zst 文件的路径和所需的输出 CSV 文件。 ","date":"2024-04-09","objectID":"/zh-cn/posts/how-to-read-a-zst-file-python/:2:5","tags":["Python"],"title":"如何通过 Python 读取 ZST 文件","uri":"/zh-cn/posts/how-to-read-a-zst-file-python/"},{"categories":["Python"],"content":"文本数据处理和分析 以下代码用于使用 Python 库（例如 pandas、用于 NMF（非负矩阵分解）主题建模的 scikit-learn 和用于文本预处理的 spaCy）从文本数据集合（在本例中为 Reddit 提交标题）中提取和分析主题 ","date":"2024-04-09","objectID":"/zh-cn/posts/how-to-read-a-zst-file-python/:3:0","tags":["Python"],"title":"如何通过 Python 读取 ZST 文件","uri":"/zh-cn/posts/how-to-read-a-zst-file-python/"},{"categories":["Python"],"content":"导入库 import pandas as pd from sklearn.feature_extraction.text import TfidfVectorizer from sklearn.decomposition import NMF import spacy 此部分导入必要的 Python 库。 pandas 用于数据处理，sklearn.feature_extraction.text 中的 TfidfVectorizer 用于将文本转换为 TF-IDF 特征矩阵，sklearn.decomposition 中的 NMF 用于主题建模，spacy 用于高级文本预处理。 ","date":"2024-04-09","objectID":"/zh-cn/posts/how-to-read-a-zst-file-python/:3:1","tags":["Python"],"title":"如何通过 Python 读取 ZST 文件","uri":"/zh-cn/posts/how-to-read-a-zst-file-python/"},{"categories":["Python"],"content":"spaCy 语言模型加载 nlp = spacy.load(\"en_core_web_sm\") 此处，英语语言模型 (en_core_web_sm) 加载到 nlp 中。此模型将用于从文本数据中标记、词形还原和删除停用词。 ","date":"2024-04-09","objectID":"/zh-cn/posts/how-to-read-a-zst-file-python/:3:2","tags":["Python"],"title":"如何通过 Python 读取 ZST 文件","uri":"/zh-cn/posts/how-to-read-a-zst-file-python/"},{"categories":["Python"],"content":"文本预处理函数 def preprocess_title(title): doc = nlp(title.lower()) return \" \".join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct and token.is_alpha]) 函数 preprocess_title 接受一个文本字符串 (title)，使用 nlp 对象对其进行标记和词形还原，并删除停用词和标点符号。然后将处理后的标记重新合并为一个字符串。词形还原将单词转换为其基本形式或字典形式，这有助于标准化同一单词的变体。 ","date":"2024-04-09","objectID":"/zh-cn/posts/how-to-read-a-zst-file-python/:3:3","tags":["Python"],"title":"如何通过 Python 读取 ZST 文件","uri":"/zh-cn/posts/how-to-read-a-zst-file-python/"},{"categories":["Python"],"content":"加载和预处理数据集 df = pd.read_csv('path_to_your_file.csv') df['processed_titles'] = df['title'].apply(preprocess_title) 此块将 CSV 文件中的数据集加载到 pandas DataFrame df 中。它假设有一个名为 'title' 的列包含要分析的文本。然后使用先前定义的 preprocess_title 函数对每个标题进行预处理。 ","date":"2024-04-09","objectID":"/zh-cn/posts/how-to-read-a-zst-file-python/:3:4","tags":["Python"],"title":"如何通过 Python 读取 ZST 文件","uri":"/zh-cn/posts/how-to-read-a-zst-file-python/"},{"categories":["Python"],"content":"TF-IDF 向量化 vectorizer = TfidfVectorizer(max_df=0.85, min_df=3, stop_words='english', ngram_range=(1,2)) tfidf = vectorizer.fit_transform(df['processed_titles']) 配置并应用 TfidfVectorizer 将预处理后的标题转换为 TF-IDF 特征矩阵。设置 max_df、min_df 和 ngram_range 等参数以过滤掉过于常见或罕见的术语，并包括二元词组以获得更丰富的特征表示。 ","date":"2024-04-09","objectID":"/zh-cn/posts/how-to-read-a-zst-file-python/:3:5","tags":["Python"],"title":"如何通过 Python 读取 ZST 文件","uri":"/zh-cn/posts/how-to-read-a-zst-file-python/"},{"categories":["Python"],"content":"使用 NMF 进行主题建模 nmf = NMF(n_components=10, random_state=42).fit(tfidf) 非负矩阵分解 (NMF) 应用于 TF-IDF 矩阵，以识别指定数量的主题 (n_components=10)。NMF 将高维 TF-IDF 矩阵分解为两个低维矩阵，揭示可以解释为主题的模式。 ","date":"2024-04-09","objectID":"/zh-cn/posts/how-to-read-a-zst-file-python/:3:6","tags":["Python"],"title":"如何通过 Python 读取 ZST 文件","uri":"/zh-cn/posts/how-to-read-a-zst-file-python/"},{"categories":["Python"],"content":"显示主题 for topic_idx, topic in enumerate(nmf.components_): print(f\"Topic #{topic_idx+1}:\") print(\" \".join([vectorizer.get_feature_names_out()[i] for i in topic.argsort()[:-10 - 1:-1]])) 对于 NMF 发现的每个主题，都会打印与该主题相关的顶级术语。这是通过按重要性降序对组件（主题）进行排序并选择顶级术语来描述每个主题来完成的。 但我认为分析结果不够好，也许以后可以尝试其他模型： ","date":"2024-04-09","objectID":"/zh-cn/posts/how-to-read-a-zst-file-python/:3:7","tags":["Python"],"title":"如何通过 Python 读取 ZST 文件","uri":"/zh-cn/posts/how-to-read-a-zst-file-python/"},{"categories":["Python"],"content":"本文介绍了如何使用 Python 进行客户分析和细分。","date":"2024-04-07","objectID":"/zh-cn/posts/customer-profiling-and-segmentation/","tags":["Python"],"title":"用Python进行顾客用户分析和细分（含源码）","uri":"/zh-cn/posts/customer-profiling-and-segmentation/"},{"categories":["Python"],"content":"本文使用的示例数据和分析代码来自Kaggle。但因为实际的运行结果与原作者不同，故在分析部分略有差异。 具体的分析流程包括： 数据准备 数据清洗 数据可视化 数据加工 聚类分析 用户画像分析 ","date":"2024-04-07","objectID":"/zh-cn/posts/customer-profiling-and-segmentation/:0:0","tags":["Python"],"title":"用Python进行顾客用户分析和细分（含源码）","uri":"/zh-cn/posts/customer-profiling-and-segmentation/"},{"categories":["Python"],"content":"1. 数据准备 使用KMeans聚类算法，将数据分成K个集群： import numpy as np import pandas as pd import seaborn as sns import matplotlib.pyplot as plt from pandas import get_dummies from sklearn.cluster import KMeans from sklearn.preprocessing import StandardScaler, LabelEncoder from yellowbrick.cluster import KElbowVisualizer import warnings warnings.filterwarnings('ignore') ","date":"2024-04-07","objectID":"/zh-cn/posts/customer-profiling-and-segmentation/:1:0","tags":["Python"],"title":"用Python进行顾客用户分析和细分（含源码）","uri":"/zh-cn/posts/customer-profiling-and-segmentation/"},{"categories":["Python"],"content":"ModuleNotFoundError: No module named ‘yellowbrick’ 出现这个错误的原因是我本地没有安装Yellowbrick这个库。 Yellowbrick是一个机器学习可视化库，主要依赖于sklearn机器学习库，能够提供多种机器学习算法的可视化。 Yellowbrick有两个主要依赖：scikit-learn和matplotlib。Yellowbrick是Python 3软件包，可与3.4或更高版本一起使用。 安装方法： pip install yellowbrick 查看数据的基本情况，共有29列： #sep是分隔符，字符型，默认值是','号。'\\t'是制表符分隔 #如果数据之前存在空格，或者说分隔符与数据之间存在空格，skipinitialspace如果指定为True，会跳过这个空格再读数据.。如果取值为False不会跳过空格，而是将空格作为数据的一部分进行读取。skipinitialspace的默认取值为False df_dataset = pd.read_csv('marketing_campaign.csv', sep='\\t', skipinitialspace = True) #根据位置返回对象的前n行，默认前5行 df_dataset.head() 查看各列的数值类型及空值情况： #info()函数用于打印DataFrame的简要摘要，显示有关DataFrame的信息，包括索引的数据类型、列的数据类型、非空值的数量、内存使用情况 df_dataset.info() ","date":"2024-04-07","objectID":"/zh-cn/posts/customer-profiling-and-segmentation/:1:1","tags":["Python"],"title":"用Python进行顾客用户分析和细分（含源码）","uri":"/zh-cn/posts/customer-profiling-and-segmentation/"},{"categories":["Python"],"content":"2. 数据清洗 已知顾客注册时间（Dt_Customer）的类型为Object。为便于后续拆分为年、月、日，需将其转换为日期时间的格式。 同时通过date()查看数据的时间跨度。由此可知数据集中customer注册时间为2012-2014年： #to_datetime()将参数转换为日期时间的格式 #Dt_Customer的原始格式是Object，并不是时间格式，需要转换 df_dataset['Dt_Customer'] = pd.to_datetime(df_dataset['Dt_Customer'], dayfirst = True) print(\"The oldest record on customer's enrollment:\", min(df_dataset['Dt_Customer']).date()) print(\"The newest record on customer's enrollment:\", max(df_dataset['Dt_Customer']).date()) ","date":"2024-04-07","objectID":"/zh-cn/posts/customer-profiling-and-segmentation/:2:0","tags":["Python"],"title":"用Python进行顾客用户分析和细分（含源码）","uri":"/zh-cn/posts/customer-profiling-and-segmentation/"},{"categories":["Python"],"content":"ValueError: time data doesn’t match to_datetime()的默认日期解析顺序是月日年，而数据集中的日期格式是日月年，故需要指定dayfirst的值： 对一些属性进行优化以便于后续的分析： 年龄（Age）：顾客记录的最近时间为2014年，以此为锚点，减去顾客的出生日期 学历情况（Education）：缩小为3个类目：Graduate、Postgraduate、Undergraduate 婚恋状况（Living_With）：缩小为2个类目：Partner、Alone 孩子数量（Total_Children）：新属性，合并“Kidhome“和”Teenhome“，表示顾客家里的孩子总数（儿童+青少年） 顾客注册时间（Dt_Customer）：拆分为天、星期几、月、年 是否已为父母（Is_Parent）：新属性，表明顾客的育儿状态 总花费（Total_Spent）：顾客的总花费 剩余特征属性维持不变 df_dataset['Age'] = 2014 - df_dataset['Year_Birth'] df_dataset['Education'] = df_dataset['Education'].replace({'Graduation':'Graduate', 'PhD':'Postgraduate', 'Master':'Postgraduate', '2n Cycle':'Postgraduate', 'Basic':'Undergraduate'}) df_dataset['Living_With'] = df_dataset['Marital_Status'].replace({'Married':'Partner', 'Together':'Partner', 'Single':'Alone', 'Divorced':'Alone', 'Widow':'Alone', 'Absurd':'Alone', 'YOLO':'Alone'}) df_dataset['Total_Children'] = df_dataset['Kidhome'] + df_dataset['Teenhome'] #把顾客注册时间拆分为具体的日、月、年以及对应的星期几 #lambda函数也叫匿名函数，即没有具体名称的函数，格式为：lambda 参数:操作（参数） #以冒号为分界线，左边是输入的变量，右边是对变量进行的操作 #利用lambda和apply函数结合，可以对DataFrame的一行或一列进行操作 df_dataset['Day'] = df_dataset['Dt_Customer'].apply(lambda x: x.day) df_dataset['Dayofweek'] = df_dataset['Dt_Customer'].apply(lambda x: x.day_name()) df_dataset['Month'] = df_dataset['Dt_Customer'].apply(lambda x: x.month) df_dataset['Year'] = df_dataset['Dt_Customer'].apply(lambda x: x.year) #若有小孩，则赋值为1，否则为0 df_dataset['Is_Parent'] = df_dataset['Total_Children'].apply(lambda x: 1 if x != 0 else 0) df_dataset['Total_Spent'] = df_dataset['MntWines'] + df_dataset['MntFruits'] + df_dataset['MntMeatProducts'] + df_dataset['MntFishProducts'] + df_dataset['MntSweetProducts'] + df_dataset['MntGoldProds'] #简化属性名称 #inplace参数的作用：为True时，不创建新的对象，直接修改原始对象；为False时，对数据进行修改，创建并返回新的对象承载其修改结果 df_dataset.rename(columns={'MntWines':'Wines', 'MntFruits':'Fruits', 'MntMeatProducts':'Meats', 'MntFishProducts':'Fish', 'MntSweetProducts':'Sweets', 'MntGoldProds':'Golds'}, inplace=True) df_dataset.rename(columns={'NumWebPurchases':'Web', 'NumCatalogPurchases':'Catalog', 'NumStorePurchases':'Store'}, inplace=True) #dropna()能够找到DataFrame类型数据的空值，将空值所在的行/列删除后，将新的DataFrame作为返回值返回 #drop()可删除表中的某一行或某一列，不改变原有的DataFrame中的数据，而是返回另一个DataFrame来存储删除后的数据 #drop()默认删除行，如果要删除列，需要添加'axis = 1' df_dataset.dropna(inplace=True) df_dataset.drop(['ID', 'Dt_Customer', 'Year_Birth', 'Marital_Status', 'Z_CostContact', 'Z_Revenue'], axis=1, inplace=True) #copy()可创建一个包含相同元素的新列表 df = df_dataset.copy() 按照顾客的收入和年龄升序排序，读取最后5行以确认是否有异常值 删除异常值：年龄大于等于80、收入金额过高 #sort_values() 可以对Dataframe的数据集按照某个字段中的数据进行排序，默认升序 #tail()读取文件的最后特定行 print('Income:') print(df['Income'].sort_values().tail(5)) print('\\nAge:') print(df['Age'].sort_values().tail(5)) #删除异常值 df = df.drop(2233) df = df[df['Age'] \u003c 80] ","date":"2024-04-07","objectID":"/zh-cn/posts/customer-profiling-and-segmentation/:2:1","tags":["Python"],"title":"用Python进行顾客用户分析和细分（含源码）","uri":"/zh-cn/posts/customer-profiling-and-segmentation/"},{"categories":["Python"],"content":"3. 数据可视化 #设置图表色系 sns.color_palette('Blues') 绘制散点矩阵图，初步观察“年龄”、“收入”、“总花费”、“消费频次“、”是否为父母“几项特征之间的关联关系： data = ['Age', 'Income', 'Total_Spent', 'Recency', 'Is_Parent'] #pairplot为散点矩阵图，用来展示两两特征之间的关系。对角线上是各个属性的直方图（分布图），非对角线上是两个不同属性之间的相关图 #hue针对某一字段进行颜色分类，palette控制色调 #suptitle()用于向图形添加居中标题，y是图形坐标中文本的y位置 plot = sns.pairplot(df[data], hue='Is_Parent', palette='Blues') plot.fig.suptitle('Feature Relationship', y=1.05, weight='bold', fontsize=16) 从图表中可以看出： 非父母人群的收入、消费金额、消费频次明显高于已为父母的人群 收入越高，人们越愿意花钱 ","date":"2024-04-07","objectID":"/zh-cn/posts/customer-profiling-and-segmentation/:3:0","tags":["Python"],"title":"用Python进行顾客用户分析和细分（含源码）","uri":"/zh-cn/posts/customer-profiling-and-segmentation/"},{"categories":["Python"],"content":"Error: 只出现标题，没有图 如果使用的Jupyter Notebook，需要在代码最前面加上 %matplotlib inline 作用是在Notebook内显示图像，而不需要显式地调用plt.show()，具体原理可参考Stackoverflow 通过条形图观察顾客注册为会员的时间分布： #在figure上创建2*2的网格 #flatten()对数组进行降维，返回一份拷贝，对拷贝所作的修改不会影响原始矩阵 #axes.flatten()把子图展开赋值给axes，则axes[0]为第一个子图，axes[1]为第二个子图，以此类推 fig, axes = plt.subplots(2,2, figsize=(15,8)) axes = axes.flatten() fig.suptitle(\"When Did the Customer Enrolled To be a Member\", weight='bold', fontsize=16) #sns.countplot用于画类别特征的频数条形图 #order对x或y的字段排序，排序的方式为列表 #ax用于指定坐标系 sns.countplot(df['Dayofweek'], order=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday','Saturday', 'Sunday'], palette='Blues', ax=axes[0]) sns.countplot(df['Day'], palette='Blues', ax=axes[1]) sns.countplot(df['Month'], palette='Blues', ax=axes[2]) sns.countplot(df['Year'], palette='Blues', ax=axes[3]) 从图表中可以看出： 多数消费者在周一、周三注册成为会员 每月第12天的注册人数明显更多 8月的注册人数最多，其次是5月、10月、3月，均超过200人 2013年的注册人数最多（但存在数据缺失问题，本数据集不包含2012年上半年和2014年下半年的数据） 把“年龄”划分为不同的区间，跨度为10： #pd.cut把一组数据分割成离散的区间，默认左边为开区间、右边为闭区间 group = pd.cut(df['Age'], [10, 20, 30, 40, 50, 60, 70, 80]) #value_counts()用于查看表格中有多少个不同值 group.value_counts() 复制一个新的数据表，在此基础上将“年龄”替换为处理后的区间数据： df2 = df.copy() #将Age列替换为已经分割后的数据 df2['Age'] = group #将顾客花费按照年龄进行分类，并分别求和、求平均数 sum_group = df2[['Total_Spent', 'Age']].groupby('Age').sum() mean_group = df2[['Total_Spent', 'Age']].groupby('Age').mean() fig, axes = plt.subplots(1,2,figsize=(14,8)) axes = axes.flatten() #barplot绘制柱状图，ci为置信区间的大小，orient为绘图方向 sns.barplot(x=sum_group['Total_Spent'], y=sum_group.index, palette='Blues', ci=None, orient='h', ax=axes[0]) axes[0].set_title('Total Spent on Products\\nby Age Groups', weight='bold', fontsize=16) #enumerate() 将一个可遍历的数据对象组合为一个索引序列，同时列出数据下标和数据 #plt.text()用于设置文字说明 #'$ {}'.format(v)给所有金额都加上货币符号 for i,v in enumerate(sum_group['Total_Spent']): if i == 0 or i ==6: axes[0].text(v+30000, i, '$ {}'.format(v), horizontalalignment='center', verticalalignment='center', weight='bold', color='black', fontsize=12) else: axes[0].text(v-40000, i, '$ {}'.format(v), horizontalalignment='center', verticalalignment='center', weight='bold', color='white', fontsize=12) sns.barplot(x=mean_group['Total_Spent'], y=mean_group.index, palette='Blues', ci=None, orient='h', ax=axes[1]) axes[1].set_title('Average Spent on Products\\nby Age Groups', weight='bold', fontsize=16) #round(v,2)保留浮点数的小数点后两位 for i,v in enumerate(mean_group['Total_Spent']): axes[1].text(v-130, i, '$ {}'.format(round(v,2)), horizontalalignment='center', verticalalignment='center', weight='bold', color='white', fontsize=12) 从图表中可以看出： 消费分布两极分化明显。两端年龄区间的人数加起来不超过20人，导致总消费金额差距明显 70岁以上人群的平均消费金额最高，超过1000美金，相当于30-40岁人群平均消费金额的两倍 观察不同年龄段人群对不同产品的消费偏好，以及各品类对公司收入的贡献： fig, axd = plt.subplot_mosaic([[0,1,2],[3,4,5], [6,6,7], [6,6,7], [6,6,7]], constrained_layout=True, figsize=(18,10)) fig.suptitle(\"Customer's Average Spent on Products\\nby Age Groups\", weight='bold', fontsize=20) #画条形图，并设置对应的图名称 sns.barplot(data=df, x=group, y='Wines', palette='Blues', ci=None, ax=axd[0]) axd[0].set_title('Wines', weight='bold') sns.barplot(data=df, x=group, y='Fruits', palette='Blues', ci=None, ax=axd[1]) axd[1].set_title('Fruits', weight='bold') sns.barplot(data=df, x=group, y='Meats', palette='Blues', ci=None, ax=axd[2]) axd[2].set_title('Meats', weight='bold') sns.barplot(data=df, x=group, y='Fish', palette='Blues', ci=None, ax=axd[3]) axd[3].set_title('Fish', weight='bold') sns.barplot(data=df, x=group, y='Sweets', palette='Blues', ci=None, ax=axd[4]) axd[4].set_title('Sweets', weight='bold') sns.barplot(data=df, x=group, y='Golds', palette='Blues', ci=None, ax=axd[5]) axd[5].set_title('Gold', weight='bold') #画饼图，对各商品类别求和后升序排列 data = df[['Wines', 'Fruits', 'Meats', 'Fish', 'Sweets', 'Golds']].sum().sort_values() #设置饼图的颜色 palette = sns.color_palette('Blues') #wedges是一个包含扇形对象的列表，texts是一个包含文本标签对象的列表，autotexts是一个包含自动生成的文本标签对象的列表 #autopct设置饼图内各个扇形百分比显示格式，'%.2f%%'为两位小数百分比，textprops为字典类型，用于指定文本标签的属性，如字体大小、字体颜色等 wedges, texts, autotexts = axd[6].pie(x=data, labels=data.index, autopct='%.2f%%', colors=palette, t","date":"2024-04-07","objectID":"/zh-cn/posts/customer-profiling-and-segmentation/:3:1","tags":["Python"],"title":"用Python进行顾客用户分析和细分（含源码）","uri":"/zh-cn/posts/customer-profiling-and-segmentation/"},{"categories":["Python"],"content":"如何使用plt.subplot_mosaic plt.subplot_mosaic可用于同时创建多个不同的子图，利用列表代表 axes 的方位，返回一个 figure 和多个 axes 参数[[0,1,2],[3,4,5], [6,6,7], [6,6,7], [6,6,7]]：这个参数定义了子图的布局。这里，我们提供了一个列表的列表（或者说是一个矩阵），其中每个子列表代表图形中的一行，列表中的每个元素代表该行中的一个子图位置。通过重复数字，我们指示某些子图跨越多行或多列。在此例中，数字6出现在三行两列的位置上，表示有一个子图跨越了这些位置 根据这段代码，最终的布局将有8个子图，布局如下： 第一行有三个子图，分别标识为0、1、2 第二行也有三个子图，分别标识为3、4、5 第三行开始，有一个较大的子图标识为6，它跨越了第三行到第五行，并占据了两列的空间。旁边是一个较小的子图标识为7 观察不同年龄段人群偏好的购物渠道，以及公司整体的订单来源： fig, axd = plt.subplot_mosaic([[0,1,2], [3,3,4], [3,3,4]], constrained_layout=True, figsize=(18,8)) fig.suptitle(\"Average Number of Purchases Made\\nThrough Different Methods by Age Groups\", weight='bold', fontsize=20) #指定y轴的范围从0到8 #plt.setp()设置子图中y轴的范围 custom_ylim = (0, 8) plt.setp(axd[0], ylim=custom_ylim) plt.setp(axd[1], ylim=custom_ylim) #按照“购买来源”分类后，绘制条形图 sns.barplot(data=df, x=group, y='Web', palette='Blues', ci=None, ax=axd[0]) axd[0].set_title('Web', weight='bold') sns.barplot(data=df, x=group, y='Catalog', palette='Blues', ci=None, ax=axd[1]) axd[1].set_title('Catalog', weight='bold') sns.barplot(data=df, x=group, y='Store', palette='Blues', ci=None, ax=axd[2]) axd[2].set_title('Store', weight='bold') #按照“购买来源”分别求和，绘制饼图 data = df[['Web', 'Catalog', 'Store']].sum().sort_values() #设置饼图颜色和细节 palette = sns.color_palette('Blues') wedges, texts, autotexts = axd[3].pie(x=data, labels=data.index, autopct='%.2f%%', colors=palette, textprops=dict(fontsize=12)); axd[3].set_title('\\n\\nPercentage of Purchases Made\\nThrough Different Methods', weight='bold', fontsize=20, x=1.35) for autotext in autotexts: autotext.set_color('white') autotext.set_weight('bold') #设置饼图数据标签的位置和展示形式 for i, (name, value) in enumerate(zip(data.index, data)): axd[3].text(2.3, 0.3-0.2*i, r\"$\\bf{\" + name + \"}$\" + \"\\t:\" + str(value) + \" times\", fontsize=14) #隐藏没有用上的图 axd[4].axis('off') 从图中可知： 在三种不同购买渠道中，70岁以上人群的消费金额都是最高的，尽管这个群组只有8人。再次反映他们的消费金额要明显高于其它年龄段的人群 将近一半的销售都直接来自于商店，占总购买额的46.2% #将列名从'Response'更改为'AcceptedCmp6'，计算顾客接受的campaign #inplace=True参数确保更改直接在原始DataFrame上进行，而不是返回一个新的DataFrame df.rename(columns={'Response':'AcceptedCmp6'}, inplace=True) plt.figure(figsize=(9,4)) plt.title('Percentage of Customer Who Accepted the nth Offer', weight='bold', fontsize=16) #df.sum()计算所有列的总和 #len(df)返回DataFrame df中的行数，这实际上是计算了每个选定列的总和占DataFrame所有行的百分比 percent = df.sum()[['AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'AcceptedCmp6']]*100/len(df) #分别通过条形图和线图绘制percent数据 #通过style='o-'参数添加了标记点，这意味着数据点以圆圈('o')标记，并通过直线('-')连接 ax = percent.plot.bar(color='#6495ED') percent.plot(style='o-', colormap='copper') plt.setp(ax, ylim=(0, 18)) #x坐标是数据点的索引i，使文本与相应的数据点对齐 #y坐标是数据点的值v加上1.2，这样做是为了将文本放置在数据点之上一定的距离，避免文本与数据点或图表其他元素重叠 for i,v in enumerate(percent): plt.text(i, v+1.2, '{:.2f}%'.format(v), horizontalalignment='center', weight='bold', color='Black', fontsize=10) 从图中可知： 愿意接受第一次campaign的人只有6.42%，第二次甚至暴跌到1.36% 第六次campaign明显吸引了大量顾客，接受率高达15.05% 观察使用折扣进行购物的人群分布，以及“是否已成为父母”这一因素的影响： plt.figure(figsize=(9,4)) plt.title('Average Number of Purchases Made with a Discount\\nby Age Groups', weight='bold', fontsize=16) #按“是否已成为父母”分别观察使用折扣进行购物的情况 sns.barplot(data=df, x=group, y='NumDealsPurchases', hue='Is_Parent', ci=None, palette='Blues') 从图中可以看出： 已成为父母的人群明显更容易被折扣吸引，进而进行购买 通过热力图观察“数值”类型的属性之间的关联关系，颜色越深，关联性越强： #从df中选取所有数值类型的列，返回这些列的列名 data = df.select_dtypes(include=[np.number]).columns plt.figure(figsize=(12,10)) plt.title('Feature correlation', weight='bold', fontsize=16, y=1.05) #绘制数值列之间的相关系数矩阵，通过热力图的颜色渐变显示相关性 sns.heatmap(df[data].corr(), cmap='Blues') 从图中可以看出： “月度官网访问次数”、“孩子总数”、“是否为父母”与顾客消费金额的相关性较小 收入、产品类别会显著影响顾客消费金额 ","date":"2024-04-07","objectID":"/zh-cn/posts/customer-profiling-and-segmentation/:3:2","tags":["Python"],"title":"用Python进行顾客用户分析和细分（含源码）","uri":"/zh-cn/posts/customer-profiling-and-segmentation/"},{"categories":["Python"],"content":"4. 数据处理 处理df中的分类特征（即非数值特征），将它们转换为虚拟变量（也称为哑变量或指示变量），然后创建一个新的DataFrame (df_final)，其中包含原始数值特征和新生成的虚拟变量： #选择df中的非数值特征并返回对应的列名 obj_feat = df.select_dtypes(exclude=[np.number]).columns #get_dummies将非数值特征转换为虚拟变量 #drop_first=True参数表示对于每个特征，去掉第一个类别的虚拟变量，以避免虚拟变量陷阱（即完全多重共线性） #concat函数沿着列(axis=1)方向将原始DataFrame (df) 和包含虚拟变量的DataFrame (dummies) 合并 #drop方法移除df_final中的原始非数值特征列，inplace=True表示在原地修改df_final，不创建新的DataFrame #df.shape获取df_final的形状，即其行数和列数 dummies = get_dummies(df[obj_feat], drop_first=True) df_final = pd.concat([df, dummies], axis=1) df_final.drop(obj_feat, axis=1, inplace=True) df_final.shape 所得结果为：(2212, 38) 使用sklearn.preprocessing中的StandardScaler对数据进行标准化处理，然后将处理后的数据转换回Pandas DataFrame格式： #StandardScaler是Scikit-learn库中的一个预处理类，用于将特征缩放到具有均值为0和标准差为1的分布 #fit_transform计算每个特征的均值和标准差，然后使用这些参数将数据进行标准化转换 scaler = StandardScaler() scaled = scaler.fit_transform(df_final) #DataFrame构造函数将scaled数组转换回DataFrame格式 #为了保持列名的一致性，使用df_final.columns作为新DataFrame的列名 #故df_final_scaled是一个新的DataFrame，其中包含了标准化后的数据，并且保留了原始DataFrame的列名 df_final_scaled = pd.DataFrame(scaled, columns=df_final.columns) df_final_scaled.head() 进行标准化处理后，数据点的值表示原始值相对于均值的偏离程度，以标准差为单位。例如，一个处理后的值为2表示该数据点的原始值比均值高出了两个标准差 使用LabelEncoder对DataFrame (df) 中的非数值特征进行编码转换，以便于之后的数据可视化： le = LabelEncoder() #通过一个for循环遍历obj_feat中的所有元素（除了最后一个元素） #先拟合obj中的数据，找出该特征中所有的唯一类别及其对应的整数编码，然后将这些唯一类别转换为整数编码 #原始DataFrame中的当前列（obj）被替换为包含转换后整数编码的trans列 for obj in obj_feat[:-1]: trans = le.fit_transform(df[obj]) df[obj] = trans ","date":"2024-04-07","objectID":"/zh-cn/posts/customer-profiling-and-segmentation/:4:0","tags":["Python"],"title":"用Python进行顾客用户分析和细分（含源码）","uri":"/zh-cn/posts/customer-profiling-and-segmentation/"},{"categories":["Python"],"content":"5. 聚类分析 此处使用\"Elbow method\"（肘部法则）进行聚类分析 ","date":"2024-04-07","objectID":"/zh-cn/posts/customer-profiling-and-segmentation/:5:0","tags":["Python"],"title":"用Python进行顾客用户分析和细分（含源码）","uri":"/zh-cn/posts/customer-profiling-and-segmentation/"},{"categories":["Python"],"content":"“Elbow method”（肘部法则）的原理 计算SSE（误差平方和）：对于每个k值（即聚类数目），我们计算所有点到其分配的聚类中心的欧几里得距离的平方和，这被称为SSE。随着k值的增加，每个聚类的大小通常会减小，因此每个点到其聚类中心的距离也会减小，导致SSE减少。 寻找“肘点”：理想情况下，我们希望找到一个较小的k值，同时保持SSE也相对较小。当我们绘制不同k值对应的SSE时，随着k值的增加，SSE的下降速度会放缓，曲线会呈现出一个“肘”形状。这个“肘点”通常被认为是最佳的聚类数量，因为在这一点之后增加更多的聚类不会显著改善模型的拟合度（即SSE的减少） 考虑到随机初始化的影响： KMeans算法在开始时会随机选择k个聚类中心，这可能导致算法结果受到初始选择的影响，从而使得最终的聚类结果具有一定的随机性。为了在多次运行或不同的环境下获得一致的结果，我们可以设置一个随机状态（random state）。 此处，通过设置random_state=123，我们确保了每次运行KMeans时聚类中心的初始随机选择是相同的，从而使得结果可复现。 ","date":"2024-04-07","objectID":"/zh-cn/posts/customer-profiling-and-segmentation/:5:1","tags":["Python"],"title":"用Python进行顾客用户分析和细分（含源码）","uri":"/zh-cn/posts/customer-profiling-and-segmentation/"},{"categories":["Python"],"content":"为什么SSE会随着k的增加而减少？ 聚类中心的增加：当我们增加聚类数量k时，意味着有更多的聚类中心可以用来表示数据点。随着聚类中心数量的增加，每个数据点更有可能被分配到离它更近的聚类中心，因此每个点到其聚类中心的平均距离会减少，导致SSE降低。 聚类大小的减小：随着k值的增加，每个聚类包含的数据点数量通常会减少。较小的聚类使得聚类内部的数据点更加紧密，减少了数据点与其聚类中心之间的距离，进一步降低了SSE。 极端情况：在极端情况下，如果k的值等于数据点的总数，那么每个数据点都是其自己的聚类中心，这时SSE将会是0。但这种情况没有实际的聚类意义，只是说明了为什么随着k的增加，SSE会持续减少。 #使用KMeans聚类算法，指定要测试的最大聚类数量为10 #KElbowVisualizer将会评估从1到10的k值，以决定哪个k值是最佳选择 #调用fit方法来训练KMeans模型 elbow = KElbowVisualizer(KMeans(random_state=123), k=10) elbow.fit(df_final_scaled) elbow.show() 运行结果是一个关于不同k值（聚类数量）与对应的SSE（误差平方和）的图表。肘部图的目的是帮助我们直观地看到随着k值增加，SSE如何变化。理想情况下，SSE随k值增加而降低，但下降速度会在某一点明显放缓，这个点就是所谓的“肘点”，被认为是最佳的聚类数量 从图中可以看出，“肘点”为k=5 #根据上图结果，创建一个聚类对象，设置聚类数量为5，即最终的目标是将数据点分成8个聚类 model = KMeans(n_clusters=5, random_state=123) #fit_predict使用预处理和标准化后的数据集来训练（拟合）KMeans模型，返回每个数据点被分配到的聚类标签，这些标签存储在yhat变量中 yhat = model.fit_predict(df_final_scaled) #将聚类结果添加到原始DataFrame中，从而能够看到每个原始数据点属于哪个聚类 df['Cluster'] = yhat #绘制每个聚类标签出现的次数 sns.countplot(data=df, x='Cluster', palette='Blues') ","date":"2024-04-07","objectID":"/zh-cn/posts/customer-profiling-and-segmentation/:5:2","tags":["Python"],"title":"用Python进行顾客用户分析和细分（含源码）","uri":"/zh-cn/posts/customer-profiling-and-segmentation/"},{"categories":["Python"],"content":"6. 用户画像分析 分析收入与总消费之间的关系，并按照聚类结果进行区分，绘制散点图和小提琴图： #constrained_layout=True确保了图形的布局自动调整以避免重叠 fig, axd = plt.subplot_mosaic([[0,0],[1,2]], constrained_layout=True, figsize=(14,8)) fig.suptitle('Income vs Total Spent', weight='bold', fontsize=16) sns.scatterplot(data=df, x='Income', y='Total_Spent', hue='Cluster', palette='Blues', ax=axd[0]) sns.violinplot(data=df, x='Cluster', y='Total_Spent', palette='Blues', ax=axd[1]) sns.violinplot(data=df, x='Cluster', y='Income', palette='Blues', ax=axd[2]) 从图中可知： 类0：高消费 \u0026 高收入 类1：低消费 \u0026 低收入 类2：平均消费 \u0026 平均收入 类3：消费最低 \u0026 收入最低 类4：消费最高 \u0026 收入最高 ","date":"2024-04-07","objectID":"/zh-cn/posts/customer-profiling-and-segmentation/:6:0","tags":["Python"],"title":"用Python进行顾客用户分析和细分（含源码）","uri":"/zh-cn/posts/customer-profiling-and-segmentation/"},{"categories":["Python"],"content":"小提琴图怎么看？ 查看宽度：小提琴图的形状可以揭示数据分布的特征。例如，如果小提琴图在某一端特别宽，则表明在那个数值附近的数据点更加密集。 分析箱线图：内嵌的箱线图提供了数据的五数概括，帮助我们了解数据的分布范围和中位数的位置。 绘制“年龄”和“总花费”的核密度估计图（KDE)： g = sns.FacetGrid(data=df, col='Cluster') g.map(sns.kdeplot, 'Age', 'Total_Spent', color='#95C8D8', fill=True) ","date":"2024-04-07","objectID":"/zh-cn/posts/customer-profiling-and-segmentation/:6:1","tags":["Python"],"title":"用Python进行顾客用户分析和细分（含源码）","uri":"/zh-cn/posts/customer-profiling-and-segmentation/"},{"categories":["Python"],"content":"核密度估计图怎么看 核密度估计图（KDE图），是一种用于展示变量分布的图形，它可以看作是直方图的平滑版本。通过KDE图，我们可以直观地了解数据的分布情况，包括数据的集中趋势、分散程度和偏态情况。以下是如何解读核密度估计图的几个要点： 峰值（Peaks）：KDE图上的峰值表示数据中的众数区域，即该值附近的数据点较多。一个图上可以有多个峰值，表明数据分布可能是多模的（即存在多个众数）。 宽度（Width）：图形的宽度反映了数据的变异性或分散程度。宽度较大的核密度图表示数据点分布较为分散；相反，宽度较窄的图表示数据点比较集中。 偏态（Skewness）：如果KDE图不是完全对称的，那么数据分布可能是偏斜的。如果图形向右延伸更长，说明数据呈正偏态（右偏），即较多的数据值位于平均值的左侧；如果图形向左延伸更长，则数据呈负偏态（左偏），即较多的数据值位于平均值的右侧。 尾部（Tails）：KDE图的尾部可以告诉我们数据分布的尾部行为，例如是否存在长尾或者极端值。长尾指的是图形的一端延伸得很长，表明存在一些极端的高值或低值。 叠加图：有时候，研究者会在同一张图上绘制多个KDE图以比较不同子集的数据分布。这时，你可以通过观察哪些区域重叠较多，以及各个图形的形状差异，来了解不同子集之间的分布差异。 核密度估计与实际数据：需要注意的是，核密度估计图表示的是对数据分布的估计，而不是实际的数据分布。因此，它对于揭示数据的整体趋势很有帮助，但可能不适合用于精确的统计测试。 绘制“是否为父母”和“总花费”的核密度估计图： g = sns.FacetGrid(data=df, col='Cluster') g.map(sns.kdeplot, 'Is_Parent', 'Total_Spent', color='#95C8D8', fill=True) plt.text(0.6,3900, '0: Non Parent\\n1: Parent', weight='bold', fontsize=12) 绘制“儿童数量”和“总花费”的核密度估计图： g = sns.FacetGrid(data=df, col='Cluster') g.map(sns.kdeplot, 'Kidhome', 'Total_Spent', color='#95C8D8', fill=True) 绘制“青少年数量”和“总花费”的核密度估计图： g = sns.FacetGrid(data=df, col='Cluster') g.map(sns.kdeplot, 'Teenhome', 'Total_Spent', color='#95C8D8', fill=True) 绘制“孩子总量”和“总花费”的核密度估计图： g = sns.FacetGrid(data=df, col='Cluster') g.map(sns.kdeplot, 'Total_Children', 'Total_Spent', color='#95C8D8', fill=True) 绘制“婚恋状况”和“总花费”的核密度估计图： g = sns.FacetGrid(data=df, col='Cluster') g.map(sns.kdeplot, 'Living_With', 'Total_Spent', color='#95C8D8', fill=True) plt.text(0.7,3900, '0: Alone\\n1: Partner', weight='bold', fontsize=12) 绘制“学历情况”和“总花费”的散点图： g = sns.FacetGrid(data=df, col='Cluster') g.map(sns.scatterplot, 'Education', 'Total_Spent', color='#95C8D8') plt.text(0.6,3400, '0: Graduate\\n1: Postgraduate\\n2: Undergraduate', weight='bold', fontsize=12) ","date":"2024-04-07","objectID":"/zh-cn/posts/customer-profiling-and-segmentation/:6:2","tags":["Python"],"title":"用Python进行顾客用户分析和细分（含源码）","uri":"/zh-cn/posts/customer-profiling-and-segmentation/"},{"categories":["Python"],"content":"散点图怎么看？ 相关性（Correlation） 正相关：如果一个变量的增加伴随着另一个变量的增加，那么这两个变量之间存在正相关。在散点图中，这表现为点集总体上从左下到右上的趋势。 负相关：如果一个变量的增加伴随着另一个变量的减少，那么这两个变量之间存在负相关。在散点图中，这表现为点集总体上从左上到右下的趋势。 无相关：如果两个变量之间没有明显的线性关系，点集在图上分布较为均匀，没有明显的趋势。 集群（Clusters） 散点图上的点有时会形成一个或多个集群，表明数据中存在不同的子群。这些集群可能代表了不同的类别、组或具有相似特征的数据点。 异常值（Outliers） 在散点图中，远离其他数据点的点称为异常值。这些点可能表示了数据录入错误、测量误差或者实际的数据分布特性。 趋势线（Trend Line） 有时在散点图上会添加一条趋势线（例如线性回归线），以更清楚地显示变量之间的主要趋势。趋势线的斜率和方向提供了变量之间关系的直观表示。 分布密度 在某些散点图中，点的密集程度可以反映数据在该区域的集中性。点越密集的区域表明那里的数据点越多。 绘制“顾客类别”与“顾客最近一次消费时间”之间的条形图： plt.figure(figsize=(9,4)) plt.title(\"Average Number of Days Since Customer's Last Purchase\\nby Clusters\", weight='bold', fontsize=16) sns.barplot(data=df, x='Cluster', y='Recency', palette='Blues', ci=None) 观察不同顾客群体（Cluster）在不同产品类别（如葡萄酒、水果、肉类等）中的平均消费额： fig, axes = plt.subplots(2,3, figsize=(16,8)) fig.suptitle(\"Customer's Average Spent on Products\\nby Clusters\", weight='bold', fontsize=20) axes = axes.flatten() sns.barplot(data=df, x='Cluster', y='Wines', palette='Blues', ci=None, ax=axes[0]) axes[0].set_title('Wines', weight='bold') sns.barplot(data=df, x='Cluster', y='Fruits', palette='Blues', ci=None, ax=axes[1]) axes[1].set_title('Fruits', weight='bold') sns.barplot(data=df, x='Cluster', y='Meats', palette='Blues', ci=None, ax=axes[2]) axes[2].set_title('Meats', weight='bold') sns.barplot(data=df, x='Cluster', y='Fish', palette='Blues', ci=None, ax=axes[3]) axes[3].set_title('Fish', weight='bold') sns.barplot(data=df, x='Cluster', y='Sweets', palette='Blues', ci=None, ax=axes[4]) axes[4].set_title('Sweets', weight='bold') sns.barplot(data=df, x='Cluster', y='Golds', palette='Blues', ci=None, ax=axes[5]) axes[5].set_title('Gold', weight='bold') #调整子图的布局，确保子图之间有足够的空间，标题和坐标轴标签不会重叠 plt.tight_layout() 观察不同顾客群体在不同销售渠道中的平均消费次数： fig, axes = plt.subplots(1,3, figsize=(16,5)) fig.suptitle(\"Average Number of Purchases Made\\nThrough Different Methods by Clusters\", weight='bold', fontsize=16) axes = axes.flatten() custom_ylim = (0, 8) plt.setp(axes[0], ylim=custom_ylim) plt.setp(axes[1], ylim=custom_ylim) sns.barplot(data=df, x='Cluster', y='Web', palette='Blues', ci=None, ax=axes[0]) axes[0].set_title('Web', weight='bold') sns.barplot(data=df, x='Cluster', y='Catalog', palette='Blues', ci=None, ax=axes[1]) axes[1].set_title('Catalog', weight='bold') sns.barplot(data=df, x='Cluster', y='Store', palette='Blues', ci=None, ax=axes[2]) axes[2].set_title('Store', weight='bold') plt.tight_layout() 观察不同顾客群体在不同营销campaign中的平均消费次数： fig, axes = plt.subplots(2,3, figsize=(16,8)) fig.suptitle(\"Average Number of Purchases Made\\nThrough Different Campaigns by Clusters\", weight='bold', fontsize=20) axes = axes.flatten() sns.barplot(data=df, x='Cluster', y='AcceptedCmp1', palette='Blues', ci=None, ax=axes[0]) axes[0].set_title('Campaign 1', weight='bold') sns.barplot(data=df, x='Cluster', y='AcceptedCmp2', palette='Blues', ci=None, ax=axes[1]) axes[1].set_title('Campaign 2', weight='bold') sns.barplot(data=df, x='Cluster', y='AcceptedCmp3', palette='Blues', ci=None, ax=axes[2]) axes[2].set_title('Campaign 3', weight='bold') sns.barplot(data=df, x='Cluster', y='AcceptedCmp4', palette='Blues', ci=None, ax=axes[3]) axes[3].set_title('Campaign 4', weight='bold') sns.barplot(data=df, x='Cluster', y='AcceptedCmp5', palette='Blues', ci=None, ax=axes[4]) axes[4].set_title('Campaign 5', weight='bold') sns.barplot(data=df, x='Cluster', y='AcceptedCmp6', palette='Blues', ci=None, ax=axes[5]) axes[5].set_title('Campaign 6', weight='bold') plt.tight_layout() 观察不同顾客群体使用折扣进行消费的情况： plt.figure(figsize=(9,4)) plt.title('Average Number of Purchases Made with a Discount\\nby Clusters', weight='bold', fontsize=16) sns.barplot(data=df, x='Cluster', y='NumDealsPurchases', ci=None, palette='Blues') 综合以上多个图表，我们可以总结出以下5类用户画像： 类0： 高消费 \u0026 高收入 跨越各个年龄段 大部分未成为父母 成为父母的，家里有1个青少年 类1： 低消费 \u0026 低收入 跨越各个年龄段 大部分已成为父母 最多3个小孩 类2： 平均消费 \u0026 平均收入 相对更年长 几乎都已成为父母，除了一小部分人 最多3个小孩，主要是青少年 热衷于用折扣进行购买 类3： 消费最低 \u0026 收入最低 相对更年轻 最多2个小孩，主要是儿童 类4： 消费最高 \u0026 收入最高 跨越各个年龄段 大部分未成为父母 6次营销campaign都积极参加 ","date":"2024-04-07","objectID":"/zh-cn/posts/customer-profiling-and-segmentation/:6:3","tags":["Python"],"title":"用Python进行顾客用户分析和细分（含源码）","uri":"/zh-cn/posts/customer-profiling-and-segmentation/"},{"categories":["SEM"],"content":"背景介绍 毕业之后我误打误撞进入了一家互联网公司负责海外推广，一年后转行做海外广告优化师，从此开启我的谷歌广告之路。推过新品、负责过高净额的产品，也经历过整个账户被封，最近开始学习招聘得力的下属。虽然这几年市场情况不乐观，但就我个人体验而言，从薪资和市场需求度的角度出发，海外广告优化师还算是一个不错的职业选择。这篇文章希望能为那些对谷歌广告优化师这个岗位感兴趣的人提供一些参考。 ","date":"2023-01-26","objectID":"/zh-cn/posts/what-does-a-google-ads-specialist-do/:1:0","tags":["SEM","谷歌广告"],"title":"谷歌广告优化师是做什么的？","uri":"/zh-cn/posts/what-does-a-google-ads-specialist-do/"},{"categories":["SEM"],"content":"概念辨析 谷歌广告优化师对英语水平要求高吗？ 在大部分情况下，是的。 一般设有海外广告优化师岗位的公司都有出海的需求，所以外语水平是一定会考核的能力。通常要求至少是英语六级水平（如果你有相关经验，可能可以放宽到英语四级水平），部分要求比较高的公司会询问你具体的六级分数，如果是刚过及格线，也有可能被看作减分项。对于小语种专业的同学，小语种会是你的加分项，但是英语水平也必须要过关。 有一种例外情况可能不会限制求职者的英语水平：该公司的目标市场人群使用的是简体中文或繁体中文。这类产品的广告投放区域大多为中国大陆、香港、澳门、台湾，部分也可能面向其它国家地区的华人群体，比如新加坡、马来西亚等。 谷歌广告优化师会很忙吗？需要经常加班吗？ 如果有同学大概了解过海外广告优化师这个岗位，可能会看到有不少从业者都在劝退，理由是“加班非常严重”、“没有个人时间”、“节假日都需要盯着账户”等等。必须承认的是，加班对于这个岗位而言是比较普遍的情况，但是不能一概而论，根据我自身以及周围相关从业者的情况，是否加班以及加班强度会受到以下两个因素的影响： 甲乙方公司 海外广告投放也是有甲乙方公司的区分的。 甲方公司指的是公司有自研的产品（游戏、软件、实体产品等），然后聘用专门人员负责这些产品的海外广告。乙方公司指的是为甲方公司提供广告管理或咨询服务的公司，业内通常称作代理商（广告代理商），规模比较大的有：木瓜移动、飞书深诺、蓝色光标等。 绝大多数情况下，乙方工作人员的加班情况会严重得多。因为甲方人员顶上天也就负责整个公司所有产品的广告账户，而乙方工作人员的手上通常至少有五家客户的广告账户，每家客户需要推广的产品数量不等。我了解到比较吓人的数字是，有位之前在百度做乙方的优化师的手里有一百多个账户。 所以，很显然，能找到甲方工作就不要去乙方公司。 在筛选岗位和公司的时候，其实很容易能够看出这个岗位是属于甲方还是乙方。以下面这个招聘信息为例： 在招聘信息当中出现类似”广告客户“、“广告主”的字眼，基本就是乙方公司的岗位了。 推广产品类型 比较常见的产品类型有：游戏、软件、实体产品（如服装、鞋袜、饰品等）。对于软件和实体产品，还会存在C端和B端的区分。一般而言，加班强度如下（先看toB还是toC，再看产品类型）： C端 \u003e B端 游戏 \u003e 实体产品（偏电商）\u003e 软件（非游戏类） 广告流量的大小和变化幅度、市场竞争程度决定了你的加班频率和强度。 另外顺便提一句，谷歌广告优化师的加班强度通常没有Facebook广告优化师的加班强度高，因为两个平台的算法机制不同，后者对数据连续性的要求比较高，由于存在时差，通常需要优化师半夜爬起来看账户是否异常。 谷歌广告优化师只负责谷歌渠道吗？相关的经验可以用到其它平台上吗？ 谷歌广告优化师通常只负责谷歌渠道，部分规模较小的公司里可能会出现一名优化师同时负责多个渠道（例如Facebook、Tiktok、Instagram等）的情况。 关于经验是否可以复用，需要根据不同平台投放和算法机制来判断。如果直接对标的话，Google广告投放的经验可以直接复用在Bing广告，但是放到Facebook广告是肯定行不通的。 ","date":"2023-01-26","objectID":"/zh-cn/posts/what-does-a-google-ads-specialist-do/:2:0","tags":["SEM","谷歌广告"],"title":"谷歌广告优化师是做什么的？","uri":"/zh-cn/posts/what-does-a-google-ads-specialist-do/"},{"categories":["SEM"],"content":"工作内容 谷歌广告优化师的日常工作包括以下几块： 监控账户流量、费用、销售等的变化情况，及时根据数据波动进行调整，确保账户稳定性 关注市场中竞品的情况，发掘新的流量和销售拓展点，建立新的投放计划 与产品、运营、设计等其他部门对接（例如广告素材需求的对接、落地页设计、网站页面故障排查等） 日常的数据统计和分析工作（日报、周报、月报等） ","date":"2023-01-26","objectID":"/zh-cn/posts/what-does-a-google-ads-specialist-do/:3:0","tags":["SEM","谷歌广告"],"title":"谷歌广告优化师是做什么的？","uri":"/zh-cn/posts/what-does-a-google-ads-specialist-do/"},{"categories":["SEM"],"content":"任职要求 Google广告优化师的任职条件其实在各大招聘软件上都可以找到，我这里大概列几点行业内的通用要求： 英语水平 前面已经提到过英语能力对于这个岗位的重要性和必要性。目前而言，英语仍然是全球使用最广泛的语言，小语种的广告只能针对特定的小语种地区进行投放。英语专业的同学最好能提供专业八级的证书。如果没有考到，也可以另外考下托福或者雅思，作为英语水平的补充证明（非英专同学如果没有拿到四级或六级证书也是一样的准备思路）。 数据分析能力 这里的数据分析并不是指SQL、建模之类比较高阶的分析能力，而是要求你对广告数据有足够的敏感度，能够通过分析广告的相关指标做出比较合理的决策和操作。账户中各个数据指标的定义不同，但彼此之前都有一定的关联，你如何找到波动的原因，如何将你的分析讲清楚，如何向你的上级解释账户数据的异常以及对应的解决方案，都要求你有一定的数据分析思维和能力。 跨团队协作能力 广告投放不是单打独斗就能做好的岗位。优化师需要对自己的广告账户数据负责，经过分析和排查后，如果异常不是来自于广告本身，而是产品出现了bug、网页无法访问等等，优化师就需要找到对应的负责人去排查和解决。“社恐”只会让自己陷入被动。 ","date":"2023-01-26","objectID":"/zh-cn/posts/what-does-a-google-ads-specialist-do/:4:0","tags":["SEM","谷歌广告"],"title":"谷歌广告优化师是做什么的？","uri":"/zh-cn/posts/what-does-a-google-ads-specialist-do/"},{"categories":["SEM"],"content":"结语 以上就是关于谷歌广告优化师这一岗位的小小分享，后续可能会再讲讲简历以及面试如何准备。 ","date":"2023-01-26","objectID":"/zh-cn/posts/what-does-a-google-ads-specialist-do/:5:0","tags":["SEM","谷歌广告"],"title":"谷歌广告优化师是做什么的？","uri":"/zh-cn/posts/what-does-a-google-ads-specialist-do/"},{"categories":["Hugo"],"content":"1. 安装Hugo Windows: 首先安装choco包管理器，在管理员权限下运行cmd，执行以下命令： markup powershell -NoProfile -ExecutionPolicy unrestricted -Command \"iex ((new-object net.webclient).DownloadString('https://chocolatey.org/install.ps1'))\" # 设置环境变量 SET PATH=%PATH%;%ALLUSERSPROFILE%\\chocolatey\\bin 然后使用choco安装hugo： choco install hugo -confirm MacOs: 使用brew命令安装： brew install hugo Linux: 使用snap命令安装： snap install hugo 检查安装是否成功： 输入：hugo version，如果出现版本信息，则安装成功。 ","date":"2022-10-20","objectID":"/zh-cn/posts/hugo-github-pages/:1:0","tags":["Hugo"],"title":"如何使用Hugo搭建博客并部署到Github","uri":"/zh-cn/posts/hugo-github-pages/"},{"categories":["Hugo"],"content":"2. Hugo 创建新站点 在 Hugo 所在的文件夹中，右键点击鼠标，选择“Bash here”，输入以下命令创建新站点： hugo new site myblog 该命令会创建一个名为 myblog 的文件夹，该文件夹是博客的根目录。站点目录结构如下： ── archetypes │ └── default.md ── config.toml # 博客站点配置文件 ── content # 博客文章所在目录 ── data ── layouts # 网站布局 ── static # 静态内容 ── themes # 博客主题 archetypes 具有预配置首选项（日期、标题、草稿等）的内容模板文件。可以使用自定义预配置的前端字段创建新的原型。 config.toml Hugo 使用 config.toml、config.yaml 或 config.json 作为默认网站配置文件。 content 存储所有内容文件。 data 存储配置文件。 layouts 将模板存储为 .html 文件。 static 存储所有静态内容，如图片、CSS、JavaScript 等。 themes 你使用的 hugo 主题。 ","date":"2022-10-20","objectID":"/zh-cn/posts/hugo-github-pages/:2:0","tags":["Hugo"],"title":"如何使用Hugo搭建博客并部署到Github","uri":"/zh-cn/posts/hugo-github-pages/"},{"categories":["Hugo"],"content":"3. 下载主题 没有主题，Hugo 就无法启动。 创建新站点后，你可以在 官方商店 中选择自己喜欢的主题。点击下载主题会跳转到主题对应的 GitHub。 首先将终端路径调整到myblog文件夹的themes目录下，然后通过git clone命令添加主题（这里以PaperMod主题为例）： cd themes #初始化git项目，博客将使用git project方式管理 git init #下载主题 git clone https://github.com/adityatelange/hugo-PaperMod.git #返回myblog文件夹，也就是你网站的根目录 cd .. #将主题添加到配置文件 $ echo theme = \"PaperMod\" \u003e\u003e config.toml 或者你也可以直接将PaperMod下的config.toml文件复制到myblog文件夹下，替换原有的config.toml文件。 ","date":"2022-10-20","objectID":"/zh-cn/posts/hugo-github-pages/:3:0","tags":["Hugo"],"title":"如何使用Hugo搭建博客并部署到Github","uri":"/zh-cn/posts/hugo-github-pages/"},{"categories":["Hugo"],"content":"解决“Error RPC failed; curl 18 transfer closed without outstanding read data remaining” 下载主题时可能会遇到此问题。主要可能有三个原因： 缓存不够大，需要增加缓存，配置： git config --global http.postBuffer 524288000 将缓存从500M设置成5G 原项目提交记录过多，配置： git clone -b master https://git.xxxxx --depth 1 -b master表示只拉取主分支的内容，可以将master改为其他分支名称；--depth 1表示只拉取最近一次提交的内容。 3.网络问题 ","date":"2022-10-20","objectID":"/zh-cn/posts/hugo-github-pages/:3:1","tags":["Hugo"],"title":"如何使用Hugo搭建博客并部署到Github","uri":"/zh-cn/posts/hugo-github-pages/"},{"categories":["Hugo"],"content":"4.创建文章 使用以下命令创建新文章： hugo new posts/helloworld.md 然后在content目录下会生成一个名为“helloworld.md”的文件。 所有文章默认放在content文件夹下。如果你有其他自定义的分类目录，则需要将文章生成到指定目录中。 每篇文章都会以以下内容开头： --- title: “Hello World” date: 2022-10-19T21:02:01+08:00 draft: true --- draft 表示“草稿”，默认值为 true，表示编译时会忽略此内容；如果改为 false，则博客会被编译使用。 ","date":"2022-10-20","objectID":"/zh-cn/posts/hugo-github-pages/:4:0","tags":["Hugo"],"title":"如何使用Hugo搭建博客并部署到Github","uri":"/zh-cn/posts/hugo-github-pages/"},{"categories":["Hugo"],"content":"5. 开始写博客 在终端输入：hugo server -D，服务默认会占用 1313 端口。 执行成功后会生成一个公共目录，这个目录下的内容就是我们创建的静态网站的所有内容。 然后在浏览器中打开 http://localhost:1313 就可以看到你的网站了。 ","date":"2022-10-20","objectID":"/zh-cn/posts/hugo-github-pages/:5:0","tags":["Hugo"],"title":"如何使用Hugo搭建博客并部署到Github","uri":"/zh-cn/posts/hugo-github-pages/"},{"categories":["Hugo"],"content":"6. 部署到GitHub页面 **GitHub Pages是静态网页（Static Web Page）的集合，这些静态网页由GitHub**托管发布，所以叫GitHub+Pages。 在Github中添加一个空白仓库，仓库名称为Github用户名.github.io，不包含任何内容，例如readme.md文件等。从这里获取Github中仓库的URL 在公共目录下，依次执行以下命令： #初始化仓库 git init #把所有东西都添加到git中 git add . #本地提交到git git commit -m \"first commit\" #关联到远程git，注意这里需要写上自己的git地址。 git remote add origin https://github.com/Githubusername/Githubusername.github.io.git #推送到远程git git push -u origin master 此时博客内容托管在Github上，你可以通过以下地址访问博客： https://Githubusername.github.io 如果后续博客内容有更新，需要使用hugo命令生成新内容，然后将新内容推送到Git仓库。 ###“fatal: ‘origin’ does not seem to be a git repository…”的解决方法 使用Git推送代码时，出现“fatal: ‘origin’ does not seem to be a git repository…”的错误提示， 原因是远程仓库名称origin不存在，可以使用下面的操作方法查看远程仓库名称及路径相关信息。可以删除错误的远程仓库名称，重新添加新的远程仓库： git remote -v：查看远程仓库详情，可以看到仓库名称 git remote remove origin：删除origin仓库（如果把origin拼成了origin，则删除错误名称的仓库） git remote add origin仓库地址：重新添加远程仓库地址 gti push -u origin master：提交到远程仓库的master trunk ","date":"2022-10-20","objectID":"/zh-cn/posts/hugo-github-pages/:6:0","tags":["Hugo"],"title":"如何使用Hugo搭建博客并部署到Github","uri":"/zh-cn/posts/hugo-github-pages/"},{"categories":["Hugo"],"content":"理解Hugo的文件夹构成 主题下载到本地后，你会看到很多个文件夹，它们可以区分为Hugo的基础文件夹（即项目创建时或用户手动添加的文件夹）以及Hugo生成静态网站后自动生成的文件夹： ","date":"2022-10-20","objectID":"/zh-cn/posts/hugo-github-pages/:7:0","tags":["Hugo"],"title":"如何使用Hugo搭建博客并部署到Github","uri":"/zh-cn/posts/hugo-github-pages/"},{"categories":["Hugo"],"content":"基础文件夹 这些文件夹在创建Hugo项目或安装主题时就已经存在，它们是你用来组织网站内容、配置、样式等的主要目录。 archetypes: 定义文章模板，帮助快速创建新内容。 content: 网站的文章和页面内容存放目录，如博客文章、页面等。 data: 用于存放结构化数据文件，可以供模板调用。 layouts: 定义页面布局和模板逻辑，控制网站的呈现方式。 static: 用于存放静态资源，如图片、CSS、JavaScript 等。这些文件会被直接复制到生成的网站中。 config.toml: 网站的配置文件，控制网站的基本设置。 themes: 用于存放网站的主题文件。LoveIt 主题就是在这个文件夹内。 此外，LoveIt主题还有一些特定的文件夹： en / zh-cn: 用于多语言支持，分开存放不同语言的内容。 js: 存放自定义的 JavaScript 文件。 lib: 存放前端库或插件（如 jQuery、FontAwesome 等）。 page: 存放特定的页面文件，如“关于我”、“联系”等页面。 posts: 存放博客文章。 svg: 存放 SVG 格式的矢量图标或图像。 tags: 生成特定标签页面，帮助通过标签组织内容。 ","date":"2022-10-20","objectID":"/zh-cn/posts/hugo-github-pages/:7:1","tags":["Hugo"],"title":"如何使用Hugo搭建博客并部署到Github","uri":"/zh-cn/posts/hugo-github-pages/"},{"categories":["Hugo"],"content":"运行Hugo后自动生成的文件夹 这些文件夹是 Hugo 在生成静态网站时创建的，它们存储的是 Hugo 处理后的输出内容或中间文件。你不需要手动创建或修改这些文件夹。 public: Hugo 执行 hugo 命令后生成的网站文件会被存放在此。它包含最终的 HTML、CSS、JS、图片等资源，准备部署到服务器上。 resources: 存放 Hugo Pipes 处理后的资源文件，如压缩后的 CSS、优化后的图片等。这些文件用于提升性能。 ","date":"2022-10-20","objectID":"/zh-cn/posts/hugo-github-pages/:7:2","tags":["Hugo"],"title":"如何使用Hugo搭建博客并部署到Github","uri":"/zh-cn/posts/hugo-github-pages/"},{"categories":["Hugo"],"content":"Hugo运行时涉及的文件夹举例 ","date":"2022-10-20","objectID":"/zh-cn/posts/hugo-github-pages/:8:0","tags":["Hugo"],"title":"如何使用Hugo搭建博客并部署到Github","uri":"/zh-cn/posts/hugo-github-pages/"},{"categories":["Hugo"],"content":"使用Hugo创建站点 创建 Hugo 站点是项目初始化的过程，Hugo会生成一些基础文件夹和文件，用于管理网站的内容、样式和功能。 操作命令： hugo new site mysite 运行过程及涉及的文件夹： archetypes: Hugo 会生成一个 archetypes/default.md 文件，这是创建新文章时的模板，定义文章的默认格式和元数据（如 title、date、tags 等）。 content: 这个文件夹最开始是空的，它是用于存放网站文章和页面的目录。你可以创建子文件夹（如 posts）来组织不同类型的内容。 data: 空的，供你存放结构化数据（如 JSON、YAML、TOML）以供模板使用。 layouts: 空的，用于存放自定义页面布局模板文件。你可以在这里创建自己的页面布局，或修改主题提供的模板。 static: 空的，存放静态文件（如图片、CSS、JS 等），这些文件会被直接复制到生成的站点中。 config.toml: 生成一个默认的配置文件，包含基础网站配置选项（如网站名称、语言、主题等）。 此外，如果你安装了主题（如 LoveIt），Hugo 会将主题文件放到 themes 文件夹中，包含主题的样式、布局、静态资源等。 创建站点后，你可以通过修改 config.toml 文件来设置站点的基本信息，比如 baseURL、languageCode、title，以及选择使用的主题。 ","date":"2022-10-20","objectID":"/zh-cn/posts/hugo-github-pages/:8:1","tags":["Hugo"],"title":"如何使用Hugo搭建博客并部署到Github","uri":"/zh-cn/posts/hugo-github-pages/"},{"categories":["Hugo"],"content":"使用Hugo创建新文章 创建新的文章（post）是基于现有站点结构，使用定义好的内容模板来生成具体的文章文件。 操作命令： hugo new posts/my-first-post.md 运行过程及涉及的文件夹： archetypes: 创建新文章时，Hugo 会从 archetypes/default.md 中读取文章模板，自动生成文章的头部元数据（Front Matter），如 title、date、draft 等。这确保每篇文章有一致的基础结构。 content/posts: 新文章会被创建在 content/posts/ 文件夹下。posts 文件夹存放的是所有的博客文章，my-first-post.md 就是刚刚创建的新文章文件。你可以通过编辑这个文件来撰写文章的内容。 文章文件通常是 markdown 格式，包含文章标题、发布时间、标签、分类等 Front Matter 信息和正文内容。 static: 如果文章中引用了图片或其他静态资源，这些资源需要放在 static 文件夹中，Hugo 会将它们复制到最终生成的站点中。 config.toml: 一些全局配置（如网站的语言、默认的主题、菜单等）可能会影响新文章的显示效果。 ","date":"2022-10-20","objectID":"/zh-cn/posts/hugo-github-pages/:8:2","tags":["Hugo"],"title":"如何使用Hugo搭建博客并部署到Github","uri":"/zh-cn/posts/hugo-github-pages/"}]